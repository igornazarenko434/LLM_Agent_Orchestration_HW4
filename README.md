# Route Enrichment Tour-Guide System

**Version:** 0.1.0  
**Package Name:** `hw4_tourguide`  
**Target Grade:** 95 (Outstanding Excellence)  
**Status:** Phase 6 - Analysis & Documentation (Research pending)

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)  
[![Pytest](https://img.shields.io/badge/pytest-passing-green.svg)](https://docs.pytest.org/)  
[![Coverage](https://img.shields.io/badge/coverage-87%25-green.svg)](htmlcov/index.html)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-black?logo=github)](https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4)

---

## üìã Table of Contents

- [Executive Summary](#1-executive-summary)
- [Problem Statement](#2-problem-statement)
- [Key Features](#3-key-features)
- [Results & Achievements](#4-results--achievements)
- [Project Structure](#5-project-structure)
- [Installation](#6-installation)
- [Quick Start](#7-quick-start)
- [Usage](#8-usage)
- [Configuration](#9-configuration)
- [Technical Architecture](#10-technical-architecture)
- [Testing](#11-testing)
- [Troubleshooting](#12-troubleshooting)
- [Research & Analysis](#13-research--analysis)
- [UX Heuristics](#14-ux-heuristics--cli-usability)
- [Quality Standards Summary](#15-quality-standards-summary)
- [Project Status](#16-project-status--roadmap)
- [Extensibility & Maintenance](#17-extensibility--maintenance)
- [Documentation](#18-documentation)
- [Contributing](#19-contributing)
- [License & Attribution](#20-license--attribution)
- [Screenshots](#21-screenshots--sample-outputs)

---

## 1. Executive Summary

The Route Enrichment Tour-Guide System is a production-grade, multi-agent orchestration platform designed to transform ordinary driving routes into immersive, content-rich journeys. By leveraging autonomous agents, concurrent processing, and intelligent judging, the system curates location-specific video, music, and knowledge content for every step of a trip.

Built as a Python package, it demonstrates advanced software engineering principles including multi-threading, circuit breakers, dependency injection, and rigorous testing, meeting the standards of a high-tech industry deliverable.

---

## 2. Problem Statement

### Challenge
Modern navigation apps provide efficient routing but lack cultural or entertainment context. Drivers and passengers often travel through historically significant or visually stunning locations without knowing what they are seeing or experiencing. Manually searching for "music related to this town" or "history of this street" while driving is unsafe and impractical.

### Solution
An automated, hands-free system that:
1.  **Ingests** a route (A to B).
2.  **Decomposes** it into navigation steps.
3.  **Dispatches** specialized agents to find relevant media (Video, Song, Knowledge) for each step in parallel.
4.  **Evaluates** content quality using an intelligent Judge.
5.  **Delivers** a structured itinerary of curated content.

### Target Personas
- **Moshe Buzaglos (Commuter):** Wants to turn boring traffic jams into educational or entertaining experiences.
- **Danit Griner (Tour Strategist):** Needs a tool to rapidly generate content-rich itineraries for clients.

---

## 3. Key Features

### Core Capabilities
- **Multi-Agent Orchestration**: Three specialized agents (Video, Song, Knowledge) run concurrently for each route step, utilizing distinct search strategies.
- **Intelligent Content Curation**: A "Judge" agent evaluates found content based on relevance, quality, and diversity, using heuristics or optional LLM-based reasoning.
- **Live & Cached Routing**: Integrates with Google Maps API for real-time routing but includes a robust caching layer to enable cost-free development and testing.
- **Persona-Based Outputs**: Generates machine-readable JSON for apps, human-readable Markdown reports for users, and CSV files for data analysis.

### Technical Excellence
- **Concurrency Model**: Utilizes `ThreadPoolExecutor` and `queue.Queue` for non-blocking, parallel execution of I/O-bound tasks (API calls).
- **Resilience Patterns**: Implements **Circuit Breakers** (ADR-010) to fail fast on API outages and **Exponential Backoff** for transient network errors.
- **Observability**: Features **Transaction ID (TID)** tracing across threads (ADR-008), structured logging, and a dedicated **Metrics Collector** (ADR-011) for performance monitoring.
- **File-Based Checkpointing**: Writes intermediate state to disk (`output/checkpoints/`) at every pipeline stage, enabling debugging and "time-travel" replay (ADR-009).
- **Hybrid Intelligence**: Agents use a "Search-Then-Fetch" architecture (ADR-004) and can toggle between heuristic-based queries and **LLM-generated queries** (ADR-013) defined in Markdown templates.

---

## 4. Results & Achievements

### Performance Metrics
- **Test Coverage**: Achieved **87%** line coverage across core modules (Target: >85%).
- **Cost Efficiency**: Caching strategy reduces API costs by **99%** for repeated runs (from ~$0.05 per live run to $0.00).
- **Concurrency**: Parallel agent execution reduces per-step processing time by approx. **60%** compared to sequential execution.

### Innovation Highlights
- **Agent Intelligence Layer**: Decoupled prompt engineering from code using Markdown-based agent definitions (`.claude/agents/*.md`). This allows refining agent behavior without redeploying the application.
- **Robustness**: The system survives individual agent failures (graceful degradation) and protects external API quotas using active circuit breaking.

---

## 5. Project Structure

```
LLM_Agent_Orchestration_HW4/
‚îú‚îÄ‚îÄ .claude/                            # Agent Intelligence Definition
‚îÇ   ‚îî‚îÄ‚îÄ agents/                         # Markdown prompt templates (Role, Context, Output)
‚îú‚îÄ‚îÄ config/                             # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ settings.yaml                   # Main config (timeouts, limits, logging)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ routes/                         # Cached route JSONs (e.g., demo_boston_mit.json)
‚îú‚îÄ‚îÄ docs/                               # Comprehensive Documentation
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                       # Research results & notebooks
‚îÇ   ‚îú‚îÄ‚îÄ architecture/                   # C4 diagrams & ADR register
‚îÇ   ‚îú‚îÄ‚îÄ contracts/                      # JSON data schemas (Task, AgentResult, Judge, Route)
‚îÇ   ‚îú‚îÄ‚îÄ quality/                        # ISO 25010 assessment
‚îÇ   ‚îú‚îÄ‚îÄ ux/                             # CLI usability heuristics
‚îÇ   ‚îú‚îÄ‚îÄ api_reference.md                # Public API & CLI reference
‚îÇ   ‚îî‚îÄ‚îÄ cost_analysis.md                # API token/cost modeling
‚îú‚îÄ‚îÄ output/                             # Generated Artifacts (Runtime)
‚îÇ   ‚îî‚îÄ‚îÄ [run_id]/                       # Per-run outputs (JSON, MD, CSV, Checkpoints)
‚îú‚îÄ‚îÄ scripts/                            # Developer Tools
‚îÇ   ‚îú‚îÄ‚îÄ check_readme.py                 # Documentation validator
‚îÇ   ‚îî‚îÄ‚îÄ preflight.py                    # Pre-submission verification suite
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ hw4_tourguide/                  # Main Package Source
‚îÇ       ‚îú‚îÄ‚îÄ agents/                     # Agent implementations (Video, Song, Knowledge)
‚îÇ       ‚îú‚îÄ‚îÄ config/                     # Packaged fallback configuration
‚îÇ       ‚îú‚îÄ‚îÄ data/                       # Packaged fallback data
‚îÇ       ‚îú‚îÄ‚îÄ prompts/                    # Packaged runtime prompt templates
‚îÇ       ‚îú‚îÄ‚îÄ tools/                      # Shared tools (Search, Fetch, LLM Client, Metrics, CircuitBreaker)
‚îÇ       ‚îú‚îÄ‚îÄ config_loader.py            # Configuration management
‚îÇ       ‚îú‚îÄ‚îÄ file_interface.py           # Checkpoint & JSON handling
‚îÇ       ‚îú‚îÄ‚îÄ judge.py                    # Evaluation logic (Heuristic + LLM)
‚îÇ       ‚îú‚îÄ‚îÄ logger.py                   # Structured logging setup
‚îÇ       ‚îú‚îÄ‚îÄ orchestrator.py             # Thread pool & task management
‚îÇ       ‚îú‚îÄ‚îÄ output_writer.py            # Report generation
‚îÇ       ‚îú‚îÄ‚îÄ route_provider.py           # Google Maps & Cache integration
‚îÇ       ‚îú‚îÄ‚îÄ scheduler.py                # Task emission logic
‚îÇ       ‚îî‚îÄ‚îÄ validators.py               # Schema validation
‚îú‚îÄ‚îÄ tests/                              # Test Suite (Pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_agent_*.py                 # Agent logic & LLM integration
‚îÇ   ‚îú‚îÄ‚îÄ test_circuit_breaker.py         # Resilience tests
‚îÇ   ‚îú‚îÄ‚îÄ test_concurrency.py             # Thread safety verification
‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py             # End-to-end pipeline tests
‚îÇ   ‚îî‚îÄ‚îÄ test_resilience.py              # Retry & backoff verification
‚îú‚îÄ‚îÄ .env.example                        # Environment variable template
‚îú‚îÄ‚îÄ .gitignore                          # Git exclusion rules
‚îú‚îÄ‚îÄ MANIFEST.in                         # Source distribution rules
‚îú‚îÄ‚îÄ Missions_Route_Enrichment_Tour_Guide_System.md  # Mission tracker
‚îú‚îÄ‚îÄ PRD_Route_Enrichment_Tour_Guide_System.md       # Product Requirements
‚îú‚îÄ‚îÄ PROGRESS_TRACKER.md                 # Execution status
‚îú‚îÄ‚îÄ README.md                           # This file
‚îî‚îÄ‚îÄ pyproject.toml                      # Build system & dependencies
```

---

## 6. Installation

### Prerequisites
- Python **3.10.19 or higher** (validated on 3.14; 3.11+ recommended)
- Git (to clone repo)
- Virtual environment (recommended)
- API keys (see `.env.example`):
  - **GOOGLE_MAPS_API_KEY** (required for `--mode live` routing). Get from Google Cloud Console ‚Üí APIs & Services ‚Üí Credentials ‚Üí API key; enable Directions & Geocoding APIs.
  - **YOUTUBE_API_KEY** (enables live VideoAgent; without it, VideoAgent uses the stub and only cached/heuristic content). Get from Google Cloud Console ‚Üí YouTube Data API v3 ‚Üí Credentials ‚Üí API key.
  - **SPOTIFY_CLIENT_ID / SPOTIFY_CLIENT_SECRET** (enables live SongAgent via Spotify; without them, SongAgent falls back to stub unless a YouTube key is present, in which case it can use YouTube as a secondary source). Create an app at https://developer.spotify.com/dashboard to obtain client ID/secret.
  - **LLM keys (optional, preferred order: Anthropic ‚Üí OpenAI ‚Üí Gemini ‚Üí Ollama ‚Üí Mock):**
    - `ANTHROPIC_API_KEY` (preferred for judge/agent LLM scoring/querying)
    - `OPENAI_API_KEY` (fallback if Anthropic missing)
    - `GEMINI_API_KEY` (fallback if Anthropic/OpenAI missing)
    - Ollama requires a local model, no key (`llm_provider=ollama`); Mock requires no key.
  - **Keyless/works offline:** cached mode and stub agents do not require any keys.

### Installation as a Library (No Git Clone)

This section guides you on how to obtain and install the `hw4_tourguide` package using distribution files (`.whl` or `.tar.gz`) directly downloaded from this repository's GitHub Releases. This is suitable for users who do not wish to clone the entire repository or build the package from source.

**How packaging works (`pyproject.toml` & `MANIFEST.in`):**
The packaging process is configured by two crucial files in the project root:
*   **`pyproject.toml`**: This modern standard defines the build system (`setuptools`), project metadata (name, version, dependencies, Python compatibility), and importantly, specifies which non-Python files (like `config/*.yaml`, `prompts/agents/*.md`, `data/routes/*.json`) should be included *inside the installed Python package* via its `[tool.setuptools.package-data]` section.
*   **`MANIFEST.in`**: This file instructs the build tools on what additional files and directories (like documentation, tests, scripts, and configuration files in the root) should be included when creating a **source distribution (`.tar.gz`)**. This ensures a complete snapshot of your repository, including non-code assets, is bundled for distribution.

**Content of Package Files:**
*   **`hw4_tourguide-X.Y.Z.tar.gz` (Source Distribution - sdist):** This archive contains your project's *source code*, `pyproject.toml`, `MANIFEST.in`, `LICENSE`, `README.md`, all `.claude/` files, `config/` files (including `config/settings.yaml`), `docs/` (documentation), `tests/` (test suite), and `scripts/` (utility scripts). It's a complete snapshot of your repository, used primarily for archiving or when a wheel isn't available for a specific environment.
*   **`hw4_tourguide-X.Y.Z-py3-none-any.whl` (Wheel Distribution - wheel):** This is a pre-built, optimized package format. It contains the compiled Python code (if any, though yours is pure Python), the `hw4_tourguide` Python package (`src/hw4_tourguide` directory), along with its bundled `config` and `data` files (as specified by `tool.setuptools.package-data` in `pyproject.toml`). Crucially, it **does NOT** include `docs/`, `tests/`, `scripts/`, or the top-level `config/` and `.claude/` folders; it only contains what's necessary for runtime. This is the recommended format for installation, as `pip` prefers wheels.

**Steps to Install from Distribution Files (downloaded from GitHub Releases):**

1.  **Create and activate a virtual environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate # For macOS/Linux
    # .venv\Scripts\Activate.ps1 # For Windows PowerShell
    ```

2.  **Download the package distribution file:**
    Navigate to the [Releases section](https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4/releases) of this repository. Download the desired `hw4_tourguide-X.Y.Z-py3-none-any.whl` file (recommended) or a `.tar.gz` to a known location on your system.
    *(Replace `X.Y.Z` with the actual version number, e.g., `0.1.0`)*

3.  **Install the package:**
    *   Navigate to the directory where you downloaded the file.
    *   Install using `pip`:
        ```bash
        pip install hw4_tourguide-X.Y.Z-py3-none-any.whl
        ```
        *(Replace `X.Y.Z` with the actual version number)*

4.  **Run your application:**
    ```bash
    python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached
    ```
    This will execute the main application, confirming your package is installed and functional.

### Step-by-Step Installation (macOS/Linux)
```bash
# 1) Clone repository
git clone https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4.git
cd LLM_Agent_Orchestration_HW4

# 2) Create virtual environment
python3 -m venv .venv   # python3.11 if available

# 3) Activate venv
source .venv/bin/activate

# 4) Upgrade pip (recommended)
pip install --upgrade pip

# 5) Install package
pip install .

# 6) (Optional) Install dev/test extras
pip install ".[dev]"

# 7) Copy env file and fill secrets
cp .env.example .env    # edit with your keys

# 8) Verify config file is present
ls config/settings.yaml

# 9) Sanity check dependencies
pip check

# 10) Run help to confirm CLI wiring
python -m hw4_tourguide --help
```

### Step-by-Step Installation (Windows PowerShell)
```powershell
# 1) Clone repository
git clone https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4.git
cd LLM_Agent_Orchestration_HW4

# 2) Create virtual environment (Python 3.10.19+; 3.11+ recommended)
py -3 -m venv .venv    # or py -3.11 -m venv .venv

# 3) Activate venv
.venv\Scripts\Activate.ps1

# 4) Upgrade pip (recommended)
python -m pip install --upgrade pip

# 5) Install package
python -m pip install .

# 6) (Optional) Dev/test extras
python -m pip install ".[dev]"

# 7) Copy env file and fill secrets
copy .env.example .env

# 8) Verify config file is present
dir config\settings.yaml

# 9) Sanity check dependencies
python -m pip check

# 10) Run help to confirm CLI wiring
python -m hw4_tourguide --help
```

Notes:
- Project metadata/deps live in `pyproject.toml`.
- Packaging inclusion rules are defined in `MANIFEST.in` (ensures config, data, and docs are included).
- Runtime config is in `config/settings.yaml`; secrets in `.env` (template: `.env.example`).
- Cached routes ship in `data/routes/`.
- Outputs/logs/checkpoints default to a per-run directory under `output/` (named `YYYY-MM-DD_HH-MM-SS_<origin>_to_<destination>`, containing JSON/MD/CSV, logs, and checkpoints). If you pass `--output custom.json`, artifacts go alongside that custom path; logs/checkpoints follow the same base.

### Installation Verification Matrix (matches PRD)

| Step | Action | Command | Expected Result | Recovery |
|------|--------|---------|-----------------|----------|
| 1 | Check Python version | `python3 --version` | Python 3.10.19+ (3.11+ recommended) | Install/activate Python 3.10.19+ |
| 2 | Clone repo | `git clone ‚Ä¶ && cd ‚Ä¶` | Repo present | Check Git/URL |
| 3 | Create venv | `python3 -m venv .venv` | `.venv` directory created | Ensure python3 on PATH |
| 4 | Activate venv | `source .venv/bin/activate` or `.venv\Scripts\Activate.ps1` | Prompt shows `(.venv)` | Use correct shell script |
| 5 | Install package | `pip install .` | Install succeeds | Inspect `pyproject.toml`, upgrade pip |
| 6 | Install dev deps (optional) | `pip install ".[dev]"` | Dev deps installed | Upgrade pip/retry |
| 7 | Copy env template | `cp .env.example .env` (or `copy` on Windows) | `.env` exists | Re-run copy; edit keys |
| 8 | Verify config present | `ls config/settings.yaml` | File listed | Restore from repo |
| 9 | Dependency health | `pip check` | No broken requirements | Reinstall deps |
|10 | Run tests | `pytest -q` | Tests pass | Run selective tests/inspect failures |
|11 | Cached run check | `python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached` | Outputs under `output/` | Ensure cached JSON exists (`data/routes/demo_boston_mit.json`) |
|12 | Live run smoke (optional) | `python -m hw4_tourguide --from "A" --to "B" --mode live` | Logs + outputs | Set API keys in `.env` |

### 6.1 Package Distribution Strategy Overview

For broader accessibility and ease of use, a proper package distribution strategy is crucial. For this project, a two-pronged approach is recommended and implemented:

1.  **PyPI Publication (Primary Distribution Channel)**
    *   **Purpose:** To enable standard, frictionless installation via `pip install hw4_tourguide` for any Python user.
    *   **Why it's a best practice:** PyPI is the official third-party package repository for Python. It simplifies dependency management and makes packages easily discoverable and installable.
    *   **Status for this project:** All local packaging configurations (`pyproject.toml`, `MANIFEST.in`, `LICENSE`) are correctly set up and verified, making the project ready for PyPI upload. *Publication to PyPI is a manual step for the developer (e.g., using `twine upload dist/*`) and is outside the scope of automated project setup.*

2.  **GitHub Releases (Complementary Distribution)**
    *   **Purpose:** To associate built package files (`.whl`, `.tar.gz`) directly with specific Git versions/tags, offering a version-controlled download source.
    *   **Why it's a best practice:** Provides a direct link between source code versions and their binary distributions, useful for showcasing releases and offering alternative download options.
    *   **Status for this project:** The `v0.1.0` tag has been created and pushed. The built `hw4_tourguide-0.1.0.tar.gz` and `hw4_tourguide-0.1.0-py3-none-any.whl` files are available locally in `dist/` and are ready to be uploaded to a new GitHub Release for the `v0.1.0` tag. *This is a manual step for the developer.*

This strategy ensures the project can be installed conventionally via `pip` (once on PyPI) or by downloading specific versioned assets directly from GitHub.

## 7. Quick Start

Pick a run mode, set your keys (if needed), and go. Default output is a per-run folder under `output/` named `YYYY-MM-DD_HH-MM-SS_<origin>_to_<destination>` containing `final_route.json`, `summary.md`, `tour_export.csv`, logs, and checkpoints. Use `--output` to place artifacts elsewhere (MD/CSV/logs/checkpoints follow that base). For granular control over LLM providers, agent behavior, and resilience settings, refer to **Section 7.1 Configuration Scenarios & Tuning** below.

> **Route length reminder:** The route retriever defaults to a maximum of **8 steps** per run (`config.route_provider.max_steps`). This keeps API usage and LLM calls bounded for demos. If you need a longer journey, bump that value in `config/settings.yaml` and rerun; the scheduler/orchestrator automatically adapts, but longer routes increase cost and runtime.

### Cached (no Google Maps calls; uses `data/routes/demo_boston_mit.json`)
```bash
python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached
```
By default agents still call live sources if keys exist (YouTube/Spotify/Wikipedia are keyless/optional). To ensure **fully offline**, set `use_live: false` or `mock_mode: true` per agent in `config/settings.yaml` (see stub/offline snippet below).

### Live (requires GOOGLE_MAPS_API_KEY; optional YouTube/Spotify/LLM keys)
```bash
python -m hw4_tourguide --from "Home" --to "Work" --mode live
```
Notes for live mode:
- If **YOUTUBE_API_KEY** is missing, VideoAgent uses the stub (no live YouTube).
- If **SPOTIFY_CLIENT_ID/SECRET** are missing, SongAgent uses the stub unless a YouTube key is present (then it can use YouTube as secondary).
- LLM keys are optional; without them, judge/agents use heuristics only.

### Custom output location
```bash
python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached --output /tmp/final.json
# Writes /tmp/final.json plus /tmp/final.md, /tmp/final.csv, and checkpoints under /tmp/checkpoints.
# Logs follow configured log directory (default: ./logs/) unless using default output path.
```

### Custom config + verbose logging
```bash
python -m hw4_tourguide --from "Boston" --to "MIT" --config config/settings.yaml --log-level DEBUG
```

### Stub/offline runs (force all agents to stub)
For full offline mode, refer to **Section 7.1 Configuration Scenarios & Tuning, Scenario B**.

### Output structure (default)
```
output/
  2025-01-01_12-00-00_Boston_MA_to_MIT/
    final_route.json
    summary.md
    final_route.csv
    checkpoints/
      <tid>/01_scheduler_queue.json
      <tid>/02_agent_search_*.json
      <tid>/03_agent_fetch_*.json
      <tid>/04_judge_decision_step_*.json
    logs/
      system.log
      errors.log
```
If you pass a custom `--output`, JSON/MD/CSV go next to that file and checkpoints under that directory; logs stay in the configured log directory (`logs/` by default).

### 7.1 Configuration Scenarios & Tuning

For advanced control, edit `config/settings.yaml`. Here are common tuning scenarios and exactly what to change:

**A. Using a Different LLM (e.g., OpenAI instead of Claude)**
By default, the system uses Anthropic (Claude). To switch to OpenAI:
1.  Ensure `OPENAI_API_KEY` is set in `.env`.
2.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      llm_provider: "openai"
    judge:
      llm_provider: "openai"
    ```

**B. Running Fully Offline (Zero Cost / No LLM)**
To disable all LLM calls (using heuristics only) and force offline stubs even if keys exist:
1.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      use_llm_for_queries: false
      video:
        use_live: false  # Forces stub
      song:
        use_live: false  # Forces stub
      knowledge:
        use_live: false  # Forces stub
    judge:
      use_llm: false
      scoring_mode: "heuristic"
    ```

**C. Disabling Secondary Sources (Strict Search)**
By default, the Song Agent falls back to YouTube if Spotify fails/misses, and Knowledge Agent uses DuckDuckGo. To restrict agents to their primary source only:
1.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      song:
        use_youtube_secondary: false
      knowledge:
        use_secondary_source: false
    ```

**D. Long Routes (>8 steps)**
The system defaults to 8 steps to prevent accidental high costs. For longer trips:
1.  Edit `config/settings.yaml`:
    ```yaml
    route_provider:
      max_steps: 20  # Increase as needed
    ```
    *Note: This linearly increases API usage and runtime.*

---

## 8. Usage

The core behavior of the system is controlled via CLI flags. For detailed control over agents, LLMs, API fallbacks, and performance tuning, refer to **Section 7.1 Configuration Scenarios & Tuning** for common adjustments, or **Section 9 Configuration** for the full schema.

### CLI (flags and what they do)
```
usage: hw4_tourguide [-h] [-v] --from ORIGIN --to DESTINATION
                     [--mode {live,cached}] [--config CONFIG]
                     [--log-level {DEBUG,INFO,WARNING,ERROR}]
                     [--output OUTPUT]
```

- `--from / --to` (required): origin/destination strings passed to route provider.
- `--mode {cached,live}` (default: cached):
  - `cached`: uses `data/routes/*.json`; no Google Maps calls. Agents still hit live sources if keys exist unless `use_live:false`/`mock_mode:true` in config.
  - `live`: calls Google Maps Directions/Geocoding (needs `GOOGLE_MAPS_API_KEY`); agents use live sources only if their keys are set.
- `--config PATH` (default: `config/settings.yaml`): central YAML for scheduler/orchestrator/agents/judge/logging/output.
- `--config PATH` (default: `config/settings.yaml`): central YAML for scheduler/orchestrator/agents/judge/logging/output. Use it to adjust `route_provider.max_steps` (default 8) when you need longer routes; increasing this directly scales API/LLM costs.
- `--log-level {DEBUG,INFO,WARNING,ERROR}` (default: INFO): overrides logging level.
- `--output PATH` (default: `output/final_route.json`): sets the JSON path; MD/CSV/checkpoints/logs follow the base rules below.
- `-v/--version`, `-h/--help`: metadata/help.

### Output behavior
- Default `--output`: creates run-specific folder under `output/` named `YYYY-MM-DD_HH-MM-SS_<origin>_to_<destination>` containing:
  - `final_route.json`, `summary.md`, `tour_export.csv`
  - `checkpoints/‚Ä¶`
  - `logs/` (system + errors)
- Custom `--output /path/to/final.json`: writes `final.json`, `final.md`, `final.csv`, and checkpoints under `/path/to/`; logs remain in configured log dir (`logs/` by default).

### Cached routes note
`CachedRouteProvider` first looks for the SHA1 slug of `"<origin>-<destination>"` (first 12 chars). For `"Boston, MA"-"MIT"` the slug is `10dac2036c05`; the repo ships `data/routes/demo_boston_mit.json` and uses it when no slug match is found.

### Route length constraint
Live routes are capped to `config.route_provider.max_steps` steps (default: **8**) to keep Google Maps/LLM costs predictable. If you exceed this bound the CLI will fail with a helpful message; edit `config/settings.yaml` and rerun if you need longer legs. This limit also ensures agents/judge stay within their search budgets.

### What each flag changes at runtime
- Route source: `--mode cached` selects `CachedRouteProvider`; `live` selects `GoogleMapsProvider`.
- Agent sources: controlled by config (`agents.*.use_live`, `mock_mode`, `use_youtube_secondary`, etc.). Keys present ‚Üí live client; missing ‚Üí stub fallback (YouTube key allows SongAgent secondary).
- Logging/output layout: driven by `--output` and `logging` section in config; default uses run-specific folder under `output/`.

---

## 9. Configuration

### YAML Configuration (`config/settings.yaml`)

The `config/settings.yaml` file is the central control panel for the entire Route Enrichment Tour-Guide System. It allows you to fine-tune the behavior of the scheduler, orchestrator, agents, judge, logging, and output. You can override any of these settings via environment variables or CLI flags (see "Configuration Priority" below).

Each parameter includes an inline comment with its type, default value, and valid range.

#### 1. Scheduler Settings (`scheduler`)
*   **Purpose:** Controls the pace at which route steps are processed.
*   `interval` (Type: `float`, Default: `2.0`, Range: `0.5-10.0` seconds)
    *   **What it does:** Defines the delay between emitting each route step to the processing queue. A lower value speeds up the simulation, while a higher value slows it down, mimicking real-world travel time more closely.
    *   **Why change it:** Adjust for faster demos (`0.5s`) or more realistic simulation (`5.0s`).
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles the scheduler daemon thread. Setting to `false` is primarily for specific testing scenarios where direct control over task emission is needed.
    *   **Why change it:** Rarely changed; keep `true` for normal operation.

#### 2. Orchestrator Settings (`orchestrator`)
*   **Purpose:** Manages the concurrent execution of agents for each route step.
*   `max_workers` (Type: `int`, Default: `5`, Range: `1-20`)
    *   **What it does:** Sets the maximum number of parallel worker threads in the `ThreadPoolExecutor`. Each worker processes a single route step, dispatching agents concurrently.
    *   **Why change it:** Increase for faster processing on systems with more CPU cores or if agents are heavily I/O bound. Decrease to limit resource usage. `5` is a good balance for 3 agents + judge.
*   `shutdown_timeout` (Type: `float`, Default: `60.0` seconds)
    *   **What it does:** The maximum time the orchestrator waits for all active workers to complete their tasks during graceful shutdown.
    *   **Why change it:** Increase if you have very long-running agent tasks or many steps to allow them to finish before forcing termination.

#### 3. Agent Configuration (`agents`)
*   **Purpose:** Controls the behavior of the Video, Song, and Knowledge Agents, including LLM integration and API usage. These are global defaults that can be overridden per-agent.
*   **`use_llm_for_queries` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
    *   **What it does:** If `true`, agents will use an LLM (selected by `llm_provider`) to generate diverse search queries based on the route context. If `false`, agents fall back to simpler heuristic-based query generation (e.g., string concatenation).
    *   **Why change it:** Set to `false` for zero LLM cost runs, faster execution (avoids LLM latency), or if you don't have an LLM API key.
*   **`llm_provider` (MOST IMPORTANT) (Type: `str`, Default: `"auto"`, Valid: `"ollama"`, `"openai"`, `"claude"`, `"gemini"`, `"mock"`)**
    *   **What it does:** Specifies which LLM service to use for query generation.
    *   **Why change it:**
        *   `"auto"` (Recommended Default): Automatically selects the first available LLM from a priority list: Anthropic (Claude) > OpenAI > Gemini > Ollama > Mock. This is ideal for flexibility.
        *   `"claude"`, `"openai"`, `"gemini"`: Explicitly select a commercial LLM (requires API key in `.env`).
        *   `"ollama"`: Use a local Ollama instance (requires Ollama server running locally).
        *   `"mock"`: Force the use of a stub LLM, returning canned responses instantly (useful for testing without any external dependencies).
*   `llm_fallback` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, and an LLM call fails (timeout, error, budget exceeded), the agent will fall back to heuristic query generation instead of failing the step.
    *   **Why change it:** Keep `true` for robust operation. Set to `false` if you require strict LLM-only query generation and want the system to fail if the LLM is unavailable.
*   `llm_max_prompt_chars` (Type: `int`, Default: `5000`)
    *   **What it does:** Limits the length of the prompt sent to the LLM to control costs and avoid exceeding context windows. Prompts longer than this will be truncated.
    *   **Why change it:** Adjust if your prompt templates or route contexts become very long.
*   `llm_max_tokens` (Type: `int`, Default: `4000`)
    *   **What it does:** The maximum total tokens an agent can use across all LLM calls during a single run. This is a safety budget.
    *   **Why change it:** Increase for longer routes or if agents generate many queries; decrease to strictly control LLM spend.
*   **Individual Agent Settings (`agents.video`, `agents.song`, `agents.knowledge`)**
    *   **Purpose:** Fine-tune the behavior of each specific content agent.
    *   **`use_live` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, the agent attempts to use its live external API (YouTube for Video, Spotify for Song, Wikipedia/DuckDuckGo for Knowledge). If `false` or API keys are missing/invalid, it uses its internal stub/mock.
        *   **Why change it:** Set to `false` to force an agent into fully offline/stub mode, regardless of API key presence (e.g., for development, testing, or demonstrations without external network calls).
    *   `mock_mode` (Type: `bool`, Default: `false`)
        *   **What it does:** Forces the agent into a deterministic mock mode. Similar to `use_live: false`, but explicitly for mocking and testing scenarios.
        *   **Why change it:** For deterministic testing and debugging. If `true`, it overrides `use_live`.
    *   `search_limit` (Type: `int`, Default: `3`, Range: `1-10`)
        *   **What it does:** The number of search results (candidates) an agent will retrieve from its primary search API.
        *   **Why change it:** Increase to give the Judge more options, potentially improving content quality but increasing API calls/cost. Decrease to reduce API calls/cost.
    *   `max_search_calls_per_run` (Type: `int`, Default: `32`)
        *   **What it does:** A safety cap on the total number of search calls an individual agent can make during a single system run. This is crucial for managing API quotas.
        *   **Why change it:** For long routes, you might need to increase this, but be mindful of external API quotas. `32` provides a good buffer for 8-step routes.
    *   **`agents.song.use_youtube_secondary` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, and the primary Spotify search fails or returns insufficient results, the Song Agent will attempt to search YouTube for music-related content as a fallback.
        *   **Why change it:** Keep `true` for maximum content coverage. Set to `false` to only use Spotify (and stub if Spotify fails).
    *   **`agents.knowledge.use_secondary_source` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, the Knowledge Agent will use DuckDuckGo as a secondary search source alongside Wikipedia (or if Wikipedia fails).
        *   **Why change it:** Keep `true` for broader knowledge coverage. Set to `false` to only use Wikipedia (and stub if Wikipedia fails).

#### 4. Judge Settings (`judge`)
*   **Purpose:** Configures how content from agents is evaluated and selected for each route step.
*   **`scoring_mode` (MOST IMPORTANT) (Type: `str`, Default: `"llm"`, Valid: `"heuristic"`, `"llm"`, `"hybrid"`)**
    *   **What it does:** Determines the method the Judge uses to score agent-provided content.
    *   **Why change it:**
        *   `"llm"` (Recommended Default): Uses an LLM to evaluate content based on semantic understanding of the route context. Provides high-quality, nuanced scores and rationales (requires LLM API key).
        *   `"heuristic"`: Uses a rule-based scoring system (e.g., presence of keywords, metadata completeness). Cost-free and deterministic, but less intelligent.
        *   `"hybrid"`: Combines both LLM and heuristic scoring.
*   **`use_llm` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
    *   **What it does:** If `true`, the Judge will attempt to use an LLM for scoring (depending on `scoring_mode`). If `false`, LLM scoring is disabled entirely.
    *   **Why change it:** Set to `false` for zero LLM cost runs, faster execution, or if you don't have an LLM API key. Note: if `scoring_mode` is "llm" or "hybrid" and `use_llm` is `false`, it effectively falls back to heuristic.
*   `llm_provider` (Type: `str`, Default: `"auto"`, Valid: `"ollama"`, `"openai"`, `"claude"`, `"gemini"`, `"mock"`)
    *   **What it does:** Same as `agents.llm_provider`, but specifically for the Judge's LLM calls.
    *   **Why change it:** To use a different LLM for judging than for agent query generation, or to explicitly set it.
*   `llm_fallback` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, and the Judge's LLM call fails, it will fall back to heuristic scoring.
    *   **Why change it:** Keep `true` for robust operation.

#### 5. Logging Settings (`logging`)
*   **Purpose:** Controls how system events, errors, and debugging information are recorded.
*   `level` (Type: `str`, Default: `"INFO"`, Valid: `"DEBUG"`, `"INFO"`, `"WARNING"`, `"ERROR"`)
    *   **What it does:** Sets the minimum severity level for messages to be logged.
    *   **Why change it:** Set to `"DEBUG"` for verbose output during development/troubleshooting. Set to `"WARNING"` or `"ERROR"` to see only critical issues.
*   `file` (Type: `str`, Default: `"logs/system.log"`)
    *   **What it does:** Path to the main log file. All general system logs go here.
*   `error_file` (Type: `str`, Default: `"logs/errors.log"`)
    *   **What it does:** Path to a dedicated log file that only contains messages of `ERROR` severity or higher.
*   `modules` (Sub-section)
    *   **Purpose:** Allows fine-grained control over logging for specific parts of the system (e.g., agents, APIs, judge).
    *   **`modules.<name>.enabled`:** Toggles logging for that module.
    *   **`modules.<name>.file`:** Sets a separate log file for the module.
    *   **`modules.<name>.level`:** Sets the specific log level for that module.
    *   **Why change it:** For deep debugging, you might set `modules.agents.level: "DEBUG"` to see verbose agent activity without cluttering the main `system.log`.

#### 6. Output Settings (`output`)
*   **Purpose:** Configures where and how the final enriched route data and checkpoints are saved.
*   `base_dir` (Type: `str`, Default: `"output"`)
    *   **What it does:** The main directory where all run-specific output folders are created (e.g., `output/2025-12-01_10-30-00_Origin_to_Destination`).
    *   **Why change it:** To centralize all outputs to a different location.
*   `json_file`, `markdown_file`, `csv_file` (Type: `str`, Default: `"output/final_route.json"`, etc.)
    *   **What it does:** Specifies the default filenames for the final JSON, Markdown, and CSV reports. When using the default `--output` CLI flag, only the filename component of these values is used within the run-specific directory.
    *   **Why change it:** To change the default names of the output files.
*   `checkpoints_enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, the system writes intermediate checkpoint files (JSON snapshots of pipeline state) at each major stage.
    *   **Why change it:** Keep `true` for debugging and auditability. Set to `false` to slightly reduce disk I/O, e.g., for performance benchmarking.
*   `checkpoint_retention_days` (Type: `int`, Default: `7`, Range: `0-30`)
    *   **What it does:** Automatically deletes checkpoint files older than this many days.
    *   **Why change it:** Set to `0` to keep checkpoints indefinitely. Adjust based on disk space and debugging needs.

#### 7. Route Provider Settings (`route_provider`)
*   **Purpose:** Defines how the system obtains the driving route.
*   **`mode` (MOST IMPORTANT) (Type: `str`, Default: `"live"`, Valid: `"live"`, `"cached"`)**
    *   **What it does:** Determines if the route is fetched live from Google Maps (`"live"`) or loaded from local JSON files (`"cached"`). This can also be set via the `--mode` CLI flag.
    *   **Why change it:** Set to `"cached"` for development, testing, and offline use to avoid Google Maps API calls and costs. Set to `"live"` for real-time route generation.
*   **`max_steps` (MOST IMPORTANT) (Type: `int`, Default: `8`, Range: `1-15`)**
    *   **What it does:** Limits the number of steps a route can have. This is a crucial control for managing API quotas and LLM costs.
    *   **Why change it:** Increase for longer trips (warning: directly increases API and LLM costs, and runtime). Decrease for shorter, cheaper runs.
*   `cache_dir` (Type: `str`, Default: `"data/routes"`)
    *   **What it does:** Directory where cached route JSON files are stored and looked up.
    *   **Why change it:** To point to a different local cache.

#### 8. Circuit Breaker Configuration (`circuit_breaker`)
*   **Purpose:** Implements the Circuit Breaker pattern to protect against cascading failures from unreliable external APIs.
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles the circuit breaker functionality globally.
    *   **Why change it:** Keep `true` for production-like resilience. Set to `false` only for specific debugging scenarios where you want API calls to always be attempted.
*   `failure_threshold` (Type: `int`, Default: `5`, Range: `3-10`)
    *   **What it does:** The number of consecutive failures before the circuit "opens", preventing further calls to the API.
    *   **Why change it:** Decrease to make the circuit breaker more sensitive (fail faster). Increase to make it more tolerant of transient errors.
*   `timeout` (Type: `float`, Default: `60.0` seconds)
    *   **What it does:** The time the circuit stays "open" before transitioning to "half-open" (allowing a single test call to check for recovery).
    *   **Why change it:** Adjust based on expected API recovery times.

#### 9. Metrics Configuration (`metrics`)
*   **Purpose:** Controls the collection and output of performance and usage metrics.
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles metrics collection.
    *   **Why change it:** Set to `false` if you do not want any performance metrics collected or written.
*   `file` (Type: `str`, Default: `"logs/metrics.json"`)
    *   **What it does:** Path to the JSON file where collected metrics are saved.
*   `update_interval` (Type: `float`, Default: `5.0` seconds)
    *   **What it does:** How often the in-memory metrics are flushed and written to the `metrics.json` file.
    *   **Why change it:** Decrease for more frequent updates (higher overhead). Increase for less frequent updates.

### Environment Variables (`.env`)

Sensitive credentials are stored in `.env` (template: `.env.example`):

```bash
# Required for live mode
GOOGLE_MAPS_API_KEY=your_key_here

# Optional for enhanced features
YOUTUBE_API_KEY=your_key_here
SPOTIFY_CLIENT_ID=your_id_here
SPOTIFY_CLIENT_SECRET=your_secret_here
OPENAI_API_KEY=your_key_here  # For LLM judge
# Knowledge agent uses Wikipedia/DuckDuckGo which are keyless (no env needed)

Agent client selection
- Video: YouTube Data API if `YOUTUBE_API_KEY` set and `use_live: true`; otherwise stub fallback.
- Song: Spotify if `SPOTIFY_CLIENT_ID/SECRET` set and `use_live: true`; optional YouTube secondary if `YOUTUBE_API_KEY` and `use_youtube_secondary: true`; otherwise stub fallback.
- Knowledge: Wikipedia + DuckDuckGo (keyless, `use_live: true` by default); stub used when `use_live: false` or `mock_mode: true`.

Live vs offline modes
- Live: leave `use_live: true` (default) and set your API keys in `.env`. Requires outbound HTTPS to `www.googleapis.com`, `api.spotify.com`, `en.wikipedia.org`, `api.duckduckgo.com`.
- Offline/stub: set `use_live: false` or `mock_mode: true` per agent in `config/settings.yaml`. Cached routes still work; agents use stubs.

Circuit breaker & metrics
- Circuit breakers wrap external calls (YouTube/Spotify/Wikipedia/DDG); open after consecutive failures to avoid hammering APIs.
- MetricsCollector writes `logs/metrics.json` with counters (`api_calls.spotify`/`youtube`/`wikipedia`) and latencies (`agent.*.search_ms`, `agent.*.fetch_ms`).
- Tests: `pytest tests/test_circuit_breaker.py tests/test_metrics_collector.py tests/test_agent_metrics.py -v`
```

See `.env.example` for complete documentation of all environment variables.

### Configuration Priority

Settings are applied in this order (later overrides earlier):
1. Code defaults
2. `config/settings.yaml`
3. Environment variables (`.env`)
4. CLI flags (highest priority)

---

## 10. Technical Architecture

### System Overview

The system implements a multi-agent, event-driven pipeline designed for resilience and observability.

```
[Route Provider] ‚îÄ‚îÄ(Task List)‚îÄ‚îÄ> [Scheduler] ‚îÄ‚îÄ(Queue)‚îÄ‚îÄ> [Orchestrator]
                                                                  ‚îÇ
                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                      ‚ñº                           ‚ñº                           ‚ñº
                                [Video Agent]               [Song Agent]              [Knowledge Agent]
                                      ‚îÇ                           ‚îÇ                           ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                  ‚îÇ                           ‚îÇ
                                                  ‚ñº                           ‚ñº
                                            [Judge Agent] ‚îÄ‚îÄ(Decision)‚îÄ‚îÄ> [Output Writer]
```

### Component Architecture

1.  **Route Provider Layer**
    - **Abstraction**: Unified `RouteProvider` interface.
    - **Implementations**: `GoogleMapsProvider` (Live API) and `CachedRouteProvider` (JSON files).
    - **Key Feature**: Aggressive caching (ADR-003) reduces API costs by 99% during development.

2.  **Orchestration Core**
    - **Scheduler**: Dedicated daemon thread emitting tasks at configurable intervals (ADR-002).
    - **Orchestrator**: Uses `ThreadPoolExecutor` (ADR-007) to manage concurrent worker threads.
    - **Synchronization**: Thread-safe `queue.Queue` handles task handoff.

3.  **Agent Framework**
    - **Pattern**: Search-then-Fetch two-phase execution (ADR-004) for cost control.
    - **Intelligence**: Markdown-defined prompts (`.claude/agents/*.md`) loaded dynamically (ADR-013).
    - **Resilience**: All external calls wrapped in **Circuit Breakers** (ADR-010) with retry/backoff logic.

4.  **Judge & Evaluation**
    - **Hybrid Scoring**: Configurable weighted heuristics with optional LLM-based semantic evaluation.
    - **Logic**: Evaluates relevance, quality, and diversity of agent findings.

### Key Innovations

- **üõ°Ô∏è Circuit Breaker Pattern (ADR-010)**: Prevents cascading failures by failing fast when external APIs (YouTube, Spotify) are down.
- **üÜî Distributed Tracing (ADR-008)**: A unique `Transaction ID (TID)` follows every request from Route to Output, enabling precise log correlation across threads.
- **üíæ File-Based Checkpoints (ADR-009)**: Every pipeline stage writes intermediate JSON artifacts (`output/checkpoints/{TID}/`), enabling "time-travel" debugging and replay.
- **üìä Separated Metrics (ADR-011)**: Performance metrics (latencies, queue depth, API counts) are tracked separately from logs in `logs/metrics.json` for real-time analysis.
- **üß† Agent Intelligence Layer (ADR-013)**: Agent prompts are decoupled from code, defined in Markdown, allowing rapid prompt engineering without redeployment.

### Execution Pipeline

1.  **Initialization**: Config loaded, secrets injected, logging/metrics subsystems started.
2.  **Route Generation**: Route fetched (Live) or loaded (Cached), split into steps.
3.  **Scheduling**: Steps emitted to the queue at a human-readable pace.
4.  **Processing**: Orchestrator dispatches steps to workers; Agents execute concurrently.
5.  **Judgment**: Judge evaluates agent results and selects the best content.
6.  **Finalization**: Results aggregated into JSON, Markdown, and CSV reports.

### Documentation References

- **[C4 Architecture Diagrams](docs/architecture/c4_diagrams.md)**: Context, Container, Component, and Deployment views.
- **[Architecture Decision Records (ADR)](docs/architecture/adr_register.md)**: Detailed rationale for all 13 architectural decisions.

## 10a. Agent Intelligence: LLM-Based Query Generation

The system now features an advanced **Agent Intelligence Layer** (ADR-013) that allows agents to generate context-aware search queries using LLMs (Claude, OpenAI, etc.) instead of static heuristics.

### Key Capabilities
- **Markdown-Defined Prompts:** Agent behaviors are defined in `.claude/agents/*.md` files, allowing prompt engineering without code changes.
- **Context Awareness:** Prompts receive rich context (location, instructions, route hints) to generate targeted queries (e.g., inferring "University" implies "campus tour").
- **Safety & Fallback:** If the LLM is slow, fails, or is disabled, agents automatically revert to heuristic logic.

### Configuration
Enable or disable this feature in `config/settings.yaml`:
```yaml
agents:
  use_llm_for_queries: true
  llm_provider: "claude"  # or "openai", "gemini", "ollama"
  llm_fallback: true      # Use heuristics on failure
```

---

## 11. Testing

### Overview
- Pytest suite (~213 tests) covering unit logic, integration flows, concurrency, resilience, CLI, clients, and outputs.
- Coverage gate: 85% (current ~87% on a clean run with dev deps).

### Test Suite Structure

#### 1. Core Pipeline & Orchestration
- `tests/test_scheduler.py`: Verifies precise interval-based task emission.
- `tests/test_orchestrator.py`: Validates thread pool management and task execution.
- `tests/test_route_provider.py`: Core routing logic (cached/live switching).
- `tests/test_route_provider_live.py`: Integration with Google Maps API.
- `tests/test_route_provider_errors.py`: Error handling for malformed routes/API failures.
- `tests/test_stub_route_provider.py`: Verifies deterministic fallback routing.

#### 2. Agents & Intelligence
- **Base Logic:** `tests/test_base_agent.py` (abstract class contracts).
- **Video Agent:** `tests/test_video_agent.py`, `tests/test_video_agent_duration.py`, `tests/test_video_agent_geosearch.py`
- **Song Agent:** `tests/test_song_agent.py`, `tests/test_song_agent_mood.py`, `tests/test_song_fallback.py` (secondary client fallback logic)
- **Knowledge Agent:** `tests/test_knowledge_agent.py`, `tests/test_knowledge_agent_authority.py`
- **LLM & Metrics:** `tests/test_agent_llm_queries.py`, `tests/test_agent_metrics.py`, `tests/test_agent_secondary.py`, `tests/test_resilience.py`

#### 3. Judge & Evaluation System
- `tests/test_judge.py`: Heuristic vs. LLM scoring logic.
- `tests/test_llm.py`: LLM provider integration (Anthropic/OpenAI/Gemini/Ollama).
- `tests/test_prompt_loader.py`: Dynamic loading of Markdown-based prompts.
- `tests/test_json_extraction.py`: Robust parsing of LLM JSON outputs.

#### 4. Resilience & Infrastructure
- **Resilience:** `tests/test_circuit_breaker.py`, `tests/test_resilience.py`, `tests/test_search_fetch.py`
- **Infrastructure:** `tests/test_config_loader.py`, `tests/test_logging.py`, `tests/test_logging_enhancements.py`, `tests/test_file_interface.py`, `tests/test_file_interface_errors.py`, `tests/test_output_writer.py`, `tests/test_metrics_collector.py`

#### 5. CLI & Entry Points
- `tests/test_cli.py`: Main entry point execution.
- `tests/test_cli_entry.py`: Argument mapping and exit codes.
- `tests/test_cli_parser.py`: Flag validation (`--mode`, `--config`).

#### 6. Integration & Concurrency
- `tests/test_integration.py`: End-to-end runs from Route -> Output.
- `tests/test_concurrency.py`: Thread safety, race condition checks, and queue integrity.

### Executing Tests

#### Quick Start
```bash
# Run all tests (fails if coverage < 85%)
pytest

# Run all tests with coverage report
pytest --cov=hw4_tourguide --cov-report=html
```

#### Targeted Execution
*Note: We use `--no-cov` for partial runs to avoid failing the global 85% coverage check.*

```bash
# Run only Agent-related tests
pytest tests/test_*_agent*.py --no-cov

# Run only Resilience tests
pytest -m resilience --no-cov

# Run a specific test file with verbose output
pytest tests/test_circuit_breaker.py -v --no-cov
```

#### Markers
The `pyproject.toml` defines strict markers for categorizing tests. Use `--no-cov` to check functionality without enforcing full coverage:

- `pytest -m unit --no-cov`: Fast, isolated tests using mocks.
- `pytest -m integration --no-cov`: Slower tests verifying component interaction.
- `pytest -m concurrency --no-cov`: Tests specifically checking thread safety.
- `pytest -m resilience --no-cov`: Tests verifying error handling and recovery.
- `pytest -m slow --no-cov`: Tests explicitly marked as slow-running.
- `pytest -m slow`: Tests explicitly marked as slow-running.

### Test Coverage & Quality

- **Target Coverage:** ‚â•85% (Enforced by CI)
- **Current Coverage:** ~87%
- **Report:** Open `htmlcov/index.html` to view line-by-line coverage analysis.

### ISO/IEC 25010 Reliability Standards

The testing strategy explicitly targets key **ISO/IEC 25010** reliability characteristics:

1.  **Fault Tolerance:**
    - Verified by `tests/test_circuit_breaker.py` and `tests/test_resilience.py`.
    - Ensures the system operates gracefully despite external API failures (YouTube/Spotify outages).
2.  **Recoverability:**
    - Verified by `tests/test_file_interface.py` (checkpoints) and `tests/test_resilience.py` (retries).
    - Ensures the system can resume from interruptions and handle transient network errors via exponential backoff.
3.  **Maturity:**
    - Verified by high coverage (~87%) across core logic (`test_orchestrator.py`, `test_scheduler.py`) and edge cases (`test_route_provider_errors.py`).
    - Ensures the system meets production stability requirements through extensive unit and integration testing.
4.  **Availability:**
    - Verified by `tests/test_concurrency.py` and `tests/test_integration.py`.
    - Ensures the system remains responsive under load (multi-threaded execution) and correctly handles resources.

---

## 12. Troubleshooting

### Common Issues and Solutions

#### 1. Import Error: No module named 'hw4_tourguide'
**Solution:** Ensure venv is activated and package installed: `pip install .`

#### 2. Missing API Key Error
**Solution:** Copy `.env.example` to `.env` and add your API keys; or use `--mode cached` with agents set to `use_live:false` if offline.

#### 3. Google Maps API Quota Exceeded
**Solution:** Switch to cached mode: `--mode cached`; wait for quota reset; ensure `max_steps` not exceeded.

#### 4. Tests Failing with Coverage Below 85%
**Solution:** Identify gaps: `pytest --cov=hw4_tourguide --cov-report=term-missing`; run targeted suites (agents/judge/clients).

#### 5. CLI Not Found After Installation
**Solution:** Activate venv; reinstall: `pip install .`; verify `python -m hw4_tourguide --help`.

#### 6. Agent returns stub/unavailable in live mode
**Cause:** Missing service keys (YouTube/Spotify) or `use_live:false`.  
**Solution:** Set keys in `.env` and ensure `use_live:true` for that agent; check circuit breaker state.

#### 7. LLM scoring/query errors
**Cause:** Missing LLM keys or prompt files; provider timeouts.  
**Solution:** Provide Anthropic/OpenAI/Gemini key, or set `use_llm:false` (judge) / `use_llm_for_queries:false` (agents). Verify prompts under `.claude/agents/` are packaged (they are).

#### 8. No outputs/logs where expected
**Cause:** Custom `--output` moves artifacts; logs stay in configured log dir.  
**Solution:** Use default `--output` to get per-run folder under `output/`; with custom output, check sibling MD/CSV and `logs/`.

#### 9. Circuit breaker opens (YouTube/Spotify/Wikipedia)
**Cause:** Repeated failures/timeouts.  
**Solution:** Wait for breaker timeout or reduce `failure_threshold`; verify network/keys; cached mode uses stubs.

For deeper troubleshooting, see `docs/troubleshooting.md` (if present) and logs/checkpoints under the run directory.

---

## 13. Research & Analysis

### Studies Planned (Phase 6)

1. **Orchestration Efficiency**: Parallelism, queue depth, system throughput
2. **Cost Analysis**: API usage tracking, live vs cached comparison
3. **Judge LLM Impact**: Heuristic vs LLM-assisted scoring quality
4. **Parameter Sensitivity**: Optimal configuration values

Results will be documented in `docs/analysis/results.ipynb` with:
- ‚â•4 plot types (bar, line, scatter, heatmap)
- LaTeX formulas for metrics
- Statistical analysis with confidence intervals

See `docs/cost_analysis.md` for API cost breakdown and optimization strategies (coming in M8.2).

---

## 14. UX Heuristics & CLI Usability

Nielsen‚Äôs 10 heuristics mapped to our CLI/log experience (see `docs/ux/heuristics.md` for full details and commands):
- **Visibility of status:** Structured logs with event tags (`Scheduler`, `Orchestrator`, `Agent`, `Judge`, `Error`). Verify: run cached with `--log-level DEBUG`, `tail -n 20 output/<run>/logs/system.log`.
- **Match to real world:** Travel-friendly flags (`--from/--to/--mode`); outputs include steps, distance, duration. Verify: `python -m hw4_tourguide --help`.
- **User control/freedom:** Choose cached vs live; force stubs via `use_live:false`/`mock_mode:true`; Ctrl+C leaves checkpoints/logs. Verify: interrupt a cached run and inspect `output/<run>/checkpoints/`.
- **Consistency/standards:** Stable flag names, log format `TIMESTAMP | LEVEL | MODULE | EVENT_TAG | MESSAGE`; config keys mirror docs. Verify: `grep -E "Scheduler|Orchestrator|Agent|Judge" output/<run>/logs/system.log`.
- **Error prevention/recovery:** Config validation, fallbacks to cached/stubs, circuit breaker warnings. Verify: `pytest tests/test_config_loader.py -k validation`; inspect warnings in logs.
- **Recognition over recall:** Sensible defaults (cached mode, default output paths, inline YAML comments), examples in `--help`. Verify: `python -m hw4_tourguide --help`.
- **Flexibility/efficiency:** YAML + CLI overrides, mock mode, adjustable intervals/workers. Verify: run with custom `--config` and `--log-level DEBUG`.
- **Minimal clutter:** Concise stdout; details in logs/MD/CSV. Verify: review `summary.md`/`tour_export.csv` in run output.

---

## 15. Quality Standards Summary

This project adheres to the **ISO/IEC 25010 Software Quality Model**, ensuring a production-grade standard of engineering. A comprehensive audit of the system against all 8 quality characteristics is available in [**docs/quality/iso_25010_assessment.md**](docs/quality/iso_25010_assessment.md).

### Key Quality Characteristics

#### üõ°Ô∏è Reliability (Outstanding)
The system is designed to be fault-tolerant and recoverable in unstable network environments.
- **Fault Tolerance:** Circuit Breakers (ADR-010) prevent cascading failures from external API outages. Verified by `tests/test_circuit_breaker.py`.
- **Recoverability:** Checkpoint system (ADR-009) persists state at every step, allowing resume-on-failure. Verified by `tests/test_file_interface.py`.
- **Maturity:** High test coverage (~87%) across happy paths and edge cases ensures stability.

#### üîß Maintainability (Outstanding)
The codebase prioritizes modularity and ease of modification.
- **Modularity:** Strict separation of concerns (Agents, Core, Tools, Interfaces) enforced by `BaseAgent` contracts. Verified by `tests/test_base_agent.py`.
- **Analyzability:** Comprehensive Architecture Decision Records (ADRs) and type-hinted code facilitate rapid understanding.
- **Testability:** Extensive unit and integration suites enable safe refactoring.

#### üß© Usability (Outstanding)
The system offers a superior Developer Experience (DX) and operational clarity.
- **Observability:** Structured, event-tagged logging facilitates rapid debugging. Verified by `tests/test_logging_enhancements.py`.
- **Error Protection:** Robust config validation falls back to safe defaults (e.g., cached mode) when keys are missing. Verified by `tests/test_config_loader.py`.
- **Clarity:** Comprehensive CLI help and consistent flag naming conventions.

#### ‚ö° Performance Efficiency (Excellent)
- **Concurrency:** Event-driven architecture with `ThreadPoolExecutor` maximizes throughput. Verified by `tests/test_concurrency.py`.
- **Resource Usage:** Aggressive caching strategies minimize expensive API calls. Verified by `tests/test_route_provider.py`.

*For the full breakdown of Functional Suitability, Compatibility, Security, and Portability, please refer to the detailed assessment document.*

---

## 16. Project Status & Roadmap

### Current Status: Phase 6 - Analysis & Documentation

**Completed (highlights):**
- ‚úÖ M0-6: PRD, architecture (C4/ADRs), config/logging, schemas, UX heuristics
- ‚úÖ M7.0-7.11: Core pipeline (Route Provider -> Scheduler -> Orchestrator -> Agents -> Judge -> Output)
- ‚úÖ M7.12-7.19: Resilience tests, LLM query generation (ADR-013), Song Agent fallback, Circuit Breakers
- ‚úÖ Gate 4: Passed (Core Implementation Complete)
- ‚úÖ M8.4-8.5: Documentation cross-check, LLM Agent Architecture docs

**In Progress:**
- üü° Phase 6: Research Analysis (M8.1) & Cost Analysis (M8.2)

**Upcoming:**
- Phase 7: Preflight + live/cached demo archive + submission

See `PROGRESS_TRACKER.md` and `Missions_Route_Enrichment_Tour_Guide_System.md` for detailed roadmap.

---

## 17. Extensibility & Maintenance

**New Features**
- New agent type: subclass `BaseAgent`, inject clients/tools, add prompt in `hw4_tourguide/prompts/agents/<agent>_agent.md`, expose config keys under `agents.<name>` in `config/settings.yaml`, and register in `_build_agents` (src/hw4_tourguide/__main__.py). Add unit + integration tests.
- New route provider: subclass `RouteProvider`, reuse retries/CB/metrics, emit the existing task schema, and wire it into `_select_route_provider` with a config flag. Include cache/checkpoint handling if applicable.
- New outputs/rerankers: extend `OutputWriter` for extra formats or add a post-search rerank hook in agents/judge; guard with config flags and keep schemas stable for JSON/MD/CSV.

**Maintenance Considerations**
- Configuration-first: document new settings in `config/settings.yaml` (with sane defaults) and keep CLI overrides consistent. Update ADRs when changing architecture.
- Prompts: maintain packaged prompts in `hw4_tourguide/prompts/agents`; keep `.claude/agents` in sync for local editing. Ensure `prompt_loader` paths stay valid.
- Observability: preserve structured logging, checkpoints, and metrics counters; keep circuit-breaker thresholds/timeouts tuned (`circuit_breaker.*`, agent timeouts, `route_provider.max_steps`).
- Contracts & tests: respect output schemas and validator expectations; keep coverage ‚â•85% with resilience/concurrency tests when touching scheduler/orchestrator/agents/judge.
- Packaging hygiene: include new data assets via `tool.setuptools.package-data` (or move defaults under `hw4_tourguide/`) so installs remain runnable without the repo checkout.

**Future Enhancements**
- Stronger LLM guardrails: stricter JSON extraction/validation for query generation and judge scoring; optional schema validation before use.
- Pluggable rerankers/judge strategies: add embedding/LLM rerank of multi-source results; make scoring mode a pluggable strategy with config toggles.
- Dynamic routing & timing: optional mid-route updates or waypoint insertion, improved scheduler timing to mirror live ETA cadence, and smarter cache priming for repeated corridors.
- Extended sources: richer secondary sources (e.g., local/offline datasets) with source weighting in judge scoring; configurable via `agents.use_secondary_source`-style flags.

---

## 18. Documentation

- **Core specs:** [PRD_Route_Enrichment_Tour_Guide_System.md](PRD_Route_Enrichment_Tour_Guide_System.md), [Missions_Route_Enrichment_Tour_Guide_System.md](Missions_Route_Enrichment_Tour_Guide_System.md), [HW4_Project_Mission.md](HW4_Project_Mission.md).
- **Architecture & APIs:** [docs/architecture/adr_register.md](docs/architecture/adr_register.md), [docs/architecture/c4_diagrams.md](docs/architecture/c4_diagrams.md), [docs/api_reference.md](docs/api_reference.md), contracts: [route_schema.json](docs/contracts/route_schema.json), [task_schema.json](docs/contracts/task_schema.json), [agent_result_schema.json](docs/contracts/agent_result_schema.json), [judge_decision_schema.json](docs/contracts/judge_decision_schema.json).
- **Research & analysis:** [docs/research_plan.md](docs/research_plan.md), [docs/analysis/results.ipynb](docs/analysis/results.ipynb), [docs/cost_analysis.md](docs/cost_analysis.md).
- **Quality & UX:** [docs/quality/iso_25010_assessment.md](docs/quality/iso_25010_assessment.md), [docs/ux/heuristics.md](docs/ux/heuristics.md).
- **Prompts & dev log:** [docs/prompt_log/](docs/prompt_log/) (e.g., [001_architecture_design_session.md](docs/prompt_log/001_architecture_design_session.md), [orchestrator_prompt.md](docs/prompt_log/orchestrator_prompt.md)); runtime prompt templates in [src/hw4_tourguide/prompts/agents/](src/hw4_tourguide/prompts/agents/) mirror `.claude/agents/`.
- **Screenshots & evidence:** [docs/screenshots/GALLERY_TEMPLATE.md](docs/screenshots/GALLERY_TEMPLATE.md) (gallery placeholder for logs/CLI/output captures).

---

## 19. Contributing

### Development Workflow
1. Fork/clone repository
2. Create venv + install deps: `pip install .` (and `".[dev]"` for tests)
3. Create feature branch: `git checkout -b feature/<name>`
4. Make changes + add tests/docs
5. Run tests: `pytest` (coverage gate 85%)
6. Commit with clear message; push branch; open PR

### Code Style & QA
- PEP8 + type hints; concise docstrings where helpful
- Add/maintain tests for new behavior; keep coverage ‚â•85%
- Prefer dependency injection for agents/tools/clients; keep modules cohesive
- Update docs/README/ADR when behavior or interfaces change

### Testing Requirements
- Run full suite: `pytest` (coverage gate 85%) before PRs; focus on concurrency/resilience tests when touching scheduler/orchestrator/agents/judge.
- Add unit/integration tests for new features or schema changes; keep deterministic outputs for JSON/MD/CSV.
- Confirm cached + live flags still parse: `python -m hw4_tourguide --help`; dry-run cached demo when touching CLI/config.
- Verify docs stay in sync when adding config flags or prompts (update README + ADRs as needed).

---

## 20. License & Attribution

- **License:** MIT (educational use for M.Sc. Data Science coursework)
- **Course:** LLMs and Multi-Agent Orchestration (Dr. Segal Yoram)
- **Date:** November 2025
- **Project:** Route Enrichment Tour-Guide System (HW4)
- **Authors:** Igor Nazarenko, Tom Ron, Roie Gilad

### Acknowledgments
- Dr. Segal Yoram for guidance
- Open-source community for core libraries

### Third-Party Libraries (key)
- requests, pyyaml, python-dotenv, pytest/pytest-cov, numpy/pandas (dev), jupyter/matplotlib/seaborn (dev)
- Optional live clients: YouTube Data API, Spotify Web API, Wikipedia/DuckDuckGo, LLM providers (Anthropic/OpenAI/Gemini/Ollama/Mock)

### Credits / References
- Architecture & ADRs: `docs/architecture/*`
- API Reference: `docs/api_reference.md`
- UX Heuristics: `docs/ux/heuristics.md`
- Quality Assessment: `docs/quality/iso_25010_assessment.md`
- References (selected):
  - Python concurrent futures (ThreadPoolExecutor): https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor
  - Prompt-template agents (Markdown definitions): https://python.langchain.com/docs/modules/model_io/prompts/
  - Multi-agent orchestration patterns (LangGraph): https://python.langchain.com/docs/langgraph/
  - Python logging best practices: https://docs.python.org/3/howto/logging-cookbook.html
  - Google Maps Directions API: https://developers.google.com/maps/documentation/directions
  - YouTube Data API v3 (search/fetch): https://developers.google.com/youtube/v3/docs
  - Spotify Web API (tracks/search): https://developer.spotify.com/documentation/web-api
  - Wikipedia REST API: https://en.wikipedia.org/api/rest_v1/
  - DuckDuckGo Instant Answer API: https://api.duckduckgo.com/api
  - Anthropic prompt design (Markdown templates): https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering
  - ISO/IEC 25010 quality model: https://iso25000.com/index.php/en/iso-25000-standards/iso-25010

### Citation
If you use this system or methodology in your work, please cite:

```bibtex
@software{route_enrichment_tourguide_2025,
  author    = {Nazarenko, Igor and Ron, Tom and Gilad, Roie},
  title     = {Route Enrichment Tour-Guide System},
  year      = {2025},
  course    = {LLMs and Multi-Agent Orchestration},
  instructor= {Dr. Segal Yoram},
  institution = {M.Sc. Data Science Program}
}
```

### Educational Value
- **Technical Skills:** Multi-agent orchestration with ThreadPoolExecutor + Queue; API client integration (Google Maps, YouTube, Spotify, Wikipedia/DDG); LLM prompt templating via packaged Markdown; circuit breakers/backoff/checkpointing; configuration-first design (YAML + CLI overrides); structured logging and metrics.
- **Problem-Solving Skills:** Cost control via cached routes and stub agents; graceful degradation when keys are missing; schema validation to keep outputs deterministic; prompt-driven behavior tuning without code changes.
- **Professional Skills:** ADR-driven architecture choices; comprehensive documentation (PRD, API reference, UX heuristics, quality audit); reproducible packaging and testing discipline (coverage gate, concurrency/resilience tests); clear CLI/README for graders and users.

---

## 21. Screenshots & Sample Outputs

A complete gallery of visual evidence is available in [docs/screenshots/GALLERY_TEMPLATE.md](docs/screenshots/GALLERY_TEMPLATE.md), where you can drop CLI, log, JSON, and Markdown snapshots that match the excerpts below.

### CLI Help Output

```
$ python -m hw4_tourguide --help
usage: hw4_tourguide [-h] [-v] [--from ORIGIN] [--to DESTINATION]
                     [--mode {live,cached}] [--config CONFIG]
                     [--log-level {DEBUG,INFO,WARNING,ERROR}] [--output OUTPUT]
...
```

### Sample Logs

```
2024-11-22 10:15:23 | INFO | Scheduler | EMIT | Step 1/5: MIT Campus (TID: abc123)
2024-11-22 10:15:25 | INFO | Orchestrator | DISPATCH | TID: abc123, Workers: 3/5 active
2024-11-22 10:15:26 | INFO | VideoAgent | SEARCH | Query: "MIT campus tour" | Results: 3 videos
2024-11-22 10:15:26 | INFO | SongAgent | SEARCH | Query: "MIT music" | Results: 3 tracks
2024-11-22 10:15:26 | INFO | KnowledgeAgent | SEARCH | Query: "MIT history" | Results: 3 articles
2024-11-22 10:15:28 | INFO | Judge | SCORE | TID: abc123 | Overall: 85, Video: 90, Song: 80, Knowledge: 85
```

These log lines are extracted from a cached run stored in `logs/system.log`; the gallery template links directly to similar captures.

### Sample Output JSON (final_route.json excerpt)
```json
[
  {
    "step_number": 1,
    "location": "MIT Campus",
    "instructions": "Head northwest on Main St",
    "agents": {
      "video": {"status": "ok", "metadata": {"title": "MIT Campus Tour", "url": "https://youtu.be/demo"}},
      "song": {"status": "ok", "metadata": {"title": "Road Trip Beats", "url": "https://open.spotify.com/track/demo"}},
      "knowledge": {"status": "ok", "metadata": {"title": "MIT History", "url": "https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology"}}
    },
    "judge": {
      "chosen_agent": "video",
      "overall_score": 90,
      "rationale": "Video best matches location context",
      "chosen_content": {"title": "MIT Campus Tour", "url": "https://youtu.be/demo"}
    }
  }
]
```

### Sample Markdown Report (summary.md excerpt)
```markdown
## Step 1: MIT Campus
Instructions: Head northwest on Main St

### Judge's Decision for MIT Campus
Chosen Content Type: **Video**
Title: [MIT Campus Tour](https://youtu.be/demo)
Overall Score: `90`
Rationale: Video best matches location context.
- Video rationale: Heuristic score breakdown: Presence=100, Quality=80, Relevance=90.
- Song rationale: Heuristic score breakdown: Presence=100, Quality=80, Relevance=70.
- Knowledge rationale: Heuristic score breakdown: Presence=100, Quality=90, Relevance=75.
```

These snippets are representative of the actual files generated under `output/<run>/final_route.json` and `output/<run>/summary.md`; capture them via the gallery link for easy reference.

See `docs/screenshots/` for terminal captures (coming in M6).

---

## 22. Support & Contact

- **Issues/PRs:** via repository tracker
- **Authors:** Igor Nazarenko, Tom Ron, Roie Gilad
- **Course:** LLMs and Multi-Agent Orchestration (Dr. Segal Yoram)

### Final Notes
- Default cached demo enables offline grading; live mode requires keys.
- Per-run outputs (JSON/MD/CSV), logs, and checkpoints provide auditability.

---

*README generated for hw4_tourguide v0.1.0 | Last updated: 2024-11-22*
