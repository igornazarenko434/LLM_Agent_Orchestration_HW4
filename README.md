# Route Enrichment Tour-Guide System

**Version:** 0.1.1  
**Package Name:** `hw4_tourguide`  
**Status:** Phase 7 - Preflight & Submission

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)  
[![Pytest](https://img.shields.io/badge/pytest-passing-green.svg)](https://docs.pytest.org/)  
[![Coverage](https://img.shields.io/badge/coverage-87%25-green.svg)](htmlcov/index.html)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repository-black?logo=github)](https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4)

---

## ðŸ“‹ Table of Contents

- [Executive Summary](#1-executive-summary)
- [Problem Statement](#2-problem-statement)
- [Key Features](#3-key-features)
- [Results & Achievements](#4-results--achievements)
- [Project Structure](#5-project-structure)
- [Installation](#6-installation)
- [Quick Start](#7-quick-start)
- [Usage](#8-usage)
- [Configuration](#9-configuration)
- [Technical Architecture](#10-technical-architecture)
- [Testing](#11-testing)
- [Troubleshooting](#12-troubleshooting)
- [Research & Analysis](#13-research--analysis)
- [UX Heuristics](#14-ux-heuristics--cli-usability)
- [Quality Standards Summary](#15-quality-standards-summary)
- [Project Status](#16-project-status--roadmap)
- [Extensibility & Maintenance](#17-extensibility--maintenance)
- [Documentation](#18-documentation)
- [Contributing](#19-contributing)
- [License & Attribution](#20-license--attribution)
- [Screenshots](#21-screenshots--sample-outputs)

---

## 1. Executive Summary

The Route Enrichment Tour-Guide System is a production-grade, multi-agent orchestration platform designed to transform ordinary driving routes into immersive, content-rich journeys. By leveraging autonomous agents, concurrent processing, and intelligent judging, the system curates location-specific video, music, and knowledge content for every step of a trip.

Built as a Python package, it demonstrates advanced software engineering principles including multi-threading, circuit breakers, dependency injection, and rigorous testing, meeting the standards of a high-tech industry deliverable.

---

## 2. Problem Statement

### Challenge
Modern navigation apps provide efficient routing but lack cultural or entertainment context. Drivers and passengers often travel through historically significant or visually stunning locations without knowing what they are seeing or experiencing. Manually searching for "music related to this town" or "history of this street" while driving is unsafe and impractical.

### Solution
An automated, hands-free system that:
1.  **Ingests** a route (A to B).
2.  **Decomposes** it into navigation steps.
3.  **Dispatches** specialized agents to find relevant media (Video, Song, Knowledge) for each step in parallel.
4.  **Evaluates** content quality using an intelligent Judge.
5.  **Delivers** a structured itinerary of curated content.

### Target Personas
- **Moshe Buzaglos (Commuter):** Wants to turn boring traffic jams into educational or entertaining experiences.
- **Danit Griner (Tour Strategist):** Needs a tool to rapidly generate content-rich itineraries for clients.

---

## 3. Key Features

### Core Capabilities
- **Multi-Agent Orchestration**: Three specialized agents (Video, Song, Knowledge) run concurrently for each route step, utilizing distinct search strategies.
- **Intelligent Content Curation**: A "Judge" agent evaluates found content based on relevance, quality, and diversity, using heuristics or optional LLM-based reasoning.
- **Live & Cached Routing**: Integrates with Google Maps API for real-time routing but includes a robust caching layer to enable cost-free development and testing.
- **Persona-Based Outputs**: Generates machine-readable JSON for apps, human-readable Markdown reports for users, and CSV files for data analysis.

### Technical Excellence
- **Concurrency Model**: Utilizes `ThreadPoolExecutor` and `queue.Queue` for non-blocking, parallel execution of I/O-bound tasks (API calls).
- **Resilience Patterns**: Implements **Circuit Breakers** (ADR-010) to fail fast on API outages and **Exponential Backoff** for transient network errors.
- **Observability**: Features **Transaction ID (TID)** tracing across threads (ADR-008), structured logging, and a dedicated **Metrics Collector** (ADR-011) for performance monitoring.
- **File-Based Checkpointing**: Writes intermediate state to disk (`output/checkpoints/`) at every pipeline stage, enabling debugging and "time-travel" replay (ADR-009).
- **Hybrid Intelligence**: Agents use a "Search-Then-Fetch" architecture (ADR-004) and can toggle between heuristic-based queries and **LLM-generated queries** (ADR-013) defined in Markdown templates.

---

## 4. Results & Achievements

### Performance Metrics
- **Test Coverage**: Achieved **87%** line coverage across core modules (Target: >85%).
- **Cost Efficiency**: Caching strategy reduces API costs by **99%** for repeated runs (from ~$0.05 per live run to $0.00).
- **Concurrency**: Parallel agent execution reduces per-step processing time by approx. **60%** compared to sequential execution.

### Innovation Highlights
- **Agent Intelligence Layer**: Decoupled prompt engineering from code using Markdown-based agent definitions (`.claude/agents/*.md`). This allows refining agent behavior without redeploying the application.
- **Robustness**: The system survives individual agent failures (graceful degradation) and protects external API quotas using active circuit breaking.

---

## 5. Project Structure

```
LLM_Agent_Orchestration_HW4/
â”œâ”€â”€ .claude/                            # Agent Intelligence Definition
â”‚   â””â”€â”€ agents/                         # Markdown prompt templates (Role, Context, Output)
â”œâ”€â”€ config/                             # Configuration
â”‚   â””â”€â”€ settings.yaml                   # Main config (timeouts, limits, logging)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ routes/                         # Cached route JSONs (e.g., demo_boston_mit.json)
â”œâ”€â”€ docs/                               # Comprehensive Documentation
â”‚   â”œâ”€â”€ analysis/                       # Research results & notebooks
â”‚   â”œâ”€â”€ architecture/                   # C4 diagrams & ADR register
â”‚   â”œâ”€â”€ contracts/                      # JSON data schemas (Task, AgentResult, Judge, Route)
â”‚   â”œâ”€â”€ quality/                        # ISO 25010 assessment
â”‚   â”œâ”€â”€ screenshots/                    # project work demonstrations and example outputs
â”‚   â”œâ”€â”€ ux/                             # CLI usability heuristics
â”‚   â”œâ”€â”€ api_reference.md                # Public API & CLI reference
â”‚   â”œâ”€â”€ research_plan.md                # research plan and methodology
â”‚   â””â”€â”€ cost_analysis.md                # API token/cost modeling
â”œâ”€â”€ output/                             # Generated Artifacts (Runtime)
â”‚   â””â”€â”€ [run_id]/                       # Per-run outputs (JSON, MD, CSV, Checkpoints, logs)
â”œâ”€â”€ scripts/                            # Developer Tools
â”‚   â”œâ”€â”€ check_readme.py                 # Documentation validator
â”‚   â”œâ”€â”€ check_api_usage.py              # Verifies API call counts and cost limits
â”‚   â”œâ”€â”€ check_scheduler_interval.py     # Verifies scheduler timing accuracy
â”‚   â”œâ”€â”€ diagnose_llm_query_generation.py     # alidates LLM query generation logic
â”‚   â””â”€â”€ preflight.py                    # Pre-submission verification suite
â”œâ”€â”€ src/
â”‚   â””â”€â”€ hw4_tourguide/                  # Main Package Source
â”‚       â”œâ”€â”€ agents/                     # Agent implementations (Video, Song, Knowledge)
â”‚       â”œâ”€â”€ config/                     # Packaged fallback configuration
â”‚       â”œâ”€â”€ data/                       # Packaged fallback data
â”‚       â”œâ”€â”€ prompts/                    # Packaged runtime prompt templates
â”‚       â”œâ”€â”€ tools/                      # Shared tools (Search, Fetch, LLM Client, Metrics, CircuitBreaker)
â”‚       â”œâ”€â”€ config_loader.py            # Configuration management
â”‚       â”œâ”€â”€ file_interface.py           # Checkpoint & JSON handling
â”‚       â”œâ”€â”€ judge.py                    # Evaluation logic (Heuristic + LLM)
â”‚       â”œâ”€â”€ logger.py                   # Structured logging setup
â”‚       â”œâ”€â”€ orchestrator.py             # Thread pool & task management
â”‚       â”œâ”€â”€ output_writer.py            # Report generation
â”‚       â”œâ”€â”€ route_provider.py           # Google Maps & Cache integration
â”‚       â”œâ”€â”€ scheduler.py                # Task emission logic
â”‚       â””â”€â”€ validators.py               # Schema validation
â”œâ”€â”€ tests/                              # Test Suite (Pytest)
â”‚   â”œâ”€â”€ test_agent_*.py                 # Agent logic & LLM integration
â”‚   â”œâ”€â”€ test_circuit_breaker.py         # Resilience tests
â”‚   â”œâ”€â”€ test_concurrency.py             # Thread safety verification
â”‚   â”œâ”€â”€ test_integration.py             # End-to-end pipeline tests
â”‚   â””â”€â”€ test_resilience.py              # Retry & backoff verification
â”œâ”€â”€ .env.example                        # Environment variable template
â”œâ”€â”€ .gitignore                          # Git exclusion rules
â”œâ”€â”€ MANIFEST.in                         # Source distribution rules
â”œâ”€â”€ Missions_Route_Enrichment_Tour_Guide_System.md  # Mission tracker
â”œâ”€â”€ PRD_Route_Enrichment_Tour_Guide_System.md       # Product Requirements
â”œâ”€â”€ PROGRESS_TRACKER.md                 # Execution status
â”œâ”€â”€ README.md                           # This file
â””â”€â”€ pyproject.toml                      # Build system & dependencies
```

---

## 6. Installation

### 6.1 Prerequisites
- **Python 3.10.19+** (3.11+ recommended).
- **Git** (for cloning the repository).
- **API Keys** (Optional for cached mode, required for live mode):
  - `GOOGLE_MAPS_API_KEY`: Directions & Geocoding.
  - `YOUTUBE_API_KEY`: Video content.
  - `SPOTIFY_CLIENT_ID` / `SPOTIFY_CLIENT_SECRET`: Music content.
  - `ANTHROPIC_API_KEY` or `OPENAI_API_KEY`: LLM Intelligence.

### 6.2 Understanding the Package Files
To make installation easy, we provide different formats:
*   **`hw4_tourguide-X.Y.Z.tar.gz` (Source Distribution):** The full source code (docs, tests, scripts). Best for developers.
*   **`hw4_tourguide-X.Y.Z-py3-none-any.whl` (Wheel):** The compiled, optimized package with bundled assets. Best for users installing as a library.
*   **`pyproject.toml` & `MANIFEST.in`:** Build configuration files that ensure the Wheel includes all necessary data (config, prompts, routes) so the system works out-of-the-box.

---

### 6.3 Option 1: Install as Library (Recommended / No Git Clone)
Use this method to run the system as a standalone tool. You do not need to clone the repository.

1.  **Download the Wheel**:
    Go to [GitHub Releases](https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4/releases) and download the latest `.whl` file.

2.  **Create & Activate Virtual Environment**:
    ```bash
    # macOS/Linux
    python3 -m venv .venv
    source .venv/bin/activate

    # Windows PowerShell
    py -3 -m venv .venv
    .venv\Scripts\Activate.ps1
    ```

3.  **Upgrade Pip & Install**:
    ```bash
    pip install --upgrade pip
    pip install hw4_tourguide-0.1.0-py3-none-any.whl  # Adjust filename as needed
    ```

4.  **Verify & Run**:
    ```bash
    # Check installation
    python -m hw4_tourguide --help

    # Run cached demo (works offline)
    python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached
    ```

---

### 6.4 Option 2: Install from Source (Clone Repository)
Use this method for development, grading, or running the test suite.

#### **macOS / Linux**
```bash
# 1) Clone repository
git clone https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4.git
cd LLM_Agent_Orchestration_HW4

# 2) Create virtual environment
python3 -m venv .venv

# 3) Activate venv
source .venv/bin/activate

# 4) Upgrade pip (Crucial for dependencies)
pip install --upgrade pip

# 5) Install package in editable mode
pip install -e .

# 6) Install development dependencies (for testing)
pip install -e ".[dev]"

# 7) Setup environment variables
cp .env.example .env
# (Edit .env with your API keys if running live mode)

# 8) Verify configuration file is present
ls config/settings.yaml

# 9) Sanity check dependencies
pip check

# 10) Run help to confirm CLI wiring
python -m hw4_tourguide --help

# 11) Run Test Suite
pytest
```

#### **Windows PowerShell**
```powershell
# 1) Clone repository
git clone https://github.com/igornazarenko434/LLM_Agent_Orchestration_HW4.git
cd LLM_Agent_Orchestration_HW4

# 2) Create virtual environment
py -3 -m venv .venv

# 3) Activate venv
.venv\Scripts\Activate.ps1

# 4) Upgrade pip
python -m pip install --upgrade pip

# 5) Install package in editable mode
python -m pip install -e .

# 6) Install development dependencies
python -m pip install -e ".[dev]"

# 7) Setup environment variables
copy .env.example .env
# (Edit .env with your API keys)

# 8) Verify configuration file is present
dir config\settings.yaml

# 9) Sanity check dependencies
python -m pip check

# 10) Run help to confirm CLI wiring
python -m hw4_tourguide --help

# 11) Run Test Suite
pytest
```

### 6.5 Installation Verification Matrix

Use this checklist to ensure the system is correctly installed and operational.

| Step | Description | Verification Command | Expected Result |
|------|-------------|----------------------|-----------------|
| 1 | **Python Version** | `python3 --version` | Output shows `Python 3.10.19` or higher. |
| 2 | **Install Success** | `pip show hw4_tourguide` | Package details (Name, Version, Location) displayed. |
| 3 | **Config Presence** | `ls config/settings.yaml` (Source only) | File exists. (Library users rely on bundled config). |
| 4 | **Dependency Health** | `pip check` | `No broken requirements found.` |
| 5 | **CLI Wiring** | `python -m hw4_tourguide --help` | Help text with `--from`, `--to`, `--mode` flags displayed. |
| 6 | **Run Tests** | `pytest` (Source only) | All tests pass (green). Coverage > 85%. |
| 7 | **Cached Run** | `python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached` | Pipeline executes, logs `Orchestrator_Task_Complete`, and saves output. |
| 8 | **Artifact Check** | `ls output/` (or check run folder) | JSON, Markdown, and CSV files are generated. |

## 7. Quick Start

Pick a run mode, set your keys (if needed), and go. Default output is a per-run folder under `output/` named `YYYY-MM-DD_HH-MM-SS_<origin>_to_<destination>` containing `final_route.json`, `summary.md`, `tour_export.csv`, logs, and checkpoints. Use `--output` to place artifacts elsewhere (MD/CSV/logs/checkpoints follow that base). For granular control over LLM providers, agent behavior, and resilience settings, refer to **Section 7.1 Configuration Scenarios & Tuning** below.

> **Route length reminder:** The route retriever defaults to a maximum of **8 steps** per run (`config.route_provider.max_steps`). This keeps API usage and LLM calls bounded for demos. If you need a longer journey, bump that value in `config/settings.yaml` and rerun; the scheduler/orchestrator automatically adapts, but longer routes increase cost and runtime.

### Cached (no Google Maps calls; uses `data/routes/demo_boston_mit.json`)
```bash
python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached
```
By default agents still call live sources if keys exist (YouTube/Spotify/Wikipedia are keyless/optional). To ensure **fully offline**, set `use_live: false` or `mock_mode: true` per agent in `config/settings.yaml` (see stub/offline snippet below).

### Live (requires GOOGLE_MAPS_API_KEY; optional YouTube/Spotify/LLM keys)
```bash
python -m hw4_tourguide --from "Home" --to "Work" --mode live
```
Notes for live mode:
- If **YOUTUBE_API_KEY** is missing, VideoAgent uses the stub (no live YouTube).
- If **SPOTIFY_CLIENT_ID/SECRET** are missing, SongAgent uses the stub unless a YouTube key is present (then it can use YouTube as secondary).
- LLM keys are optional; without them, judge/agents use heuristics only.

### Custom output location
```bash
python -m hw4_tourguide --from "Boston, MA" --to "MIT" --mode cached --output /tmp/final.json
# Writes /tmp/final.json plus /tmp/final.md, /tmp/final.csv, and checkpoints under /tmp/checkpoints.
# Logs follow configured log directory (default: ./logs/) unless using default output path.
```

### Custom config + verbose logging
```bash
python -m hw4_tourguide --from "Boston" --to "MIT" --config config/settings.yaml --log-level DEBUG
```

### Stub/offline runs (force all agents to stub)
For full offline mode, refer to **Section 7.1 Configuration Scenarios & Tuning, Scenario B**.

### Output structure (default)
```
output/
  2025-01-01_12-00-00_Boston_MA_to_MIT/
    final_route.json
    summary.md
    final_route.csv
    checkpoints/
      <tid>/01_scheduler_queue.json
      <tid>/02_agent_search_*.json
      <tid>/03_agent_fetch_*.json
      <tid>/04_judge_decision_step_*.json
    logs/
      system.log
      errors.log
```
If you pass a custom `--output`, JSON/MD/CSV go next to that file and checkpoints under that directory; logs stay in the configured log directory (`logs/` by default).

### 7.1 Configuration Scenarios & Tuning

For advanced control, edit `config/settings.yaml`. Here are common tuning scenarios and exactly what to change:

**A. Using a Different LLM (e.g., OpenAI instead of Claude)**
By default, the system uses Anthropic (Claude). To switch to OpenAI:
1.  Ensure `OPENAI_API_KEY` is set in `.env`.
2.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      llm_provider: "openai"
    judge:
      llm_provider: "openai"
    ```

**B. Running Fully Offline (Zero Cost / No LLM)**
To disable all LLM calls (using heuristics only) and force offline stubs even if keys exist:
1.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      use_llm_for_queries: false
      video:
        use_live: false  # Forces stub
      song:
        use_live: false  # Forces stub
      knowledge:
        use_live: false  # Forces stub
    judge:
      use_llm: false
      scoring_mode: "heuristic"
    ```

**C. Disabling Secondary Sources (Strict Search)**
By default, the Song Agent falls back to YouTube if Spotify fails/misses, and Knowledge Agent uses DuckDuckGo. To restrict agents to their primary source only:
1.  Edit `config/settings.yaml`:
    ```yaml
    agents:
      song:
        use_youtube_secondary: false
      knowledge:
        use_secondary_source: false
    ```

**D. Long Routes (>8 steps)**
The system defaults to 8 steps to prevent accidental high costs. For longer trips:
1.  Edit `config/settings.yaml`:
    ```yaml
    route_provider:
      max_steps: 20  # Increase as needed
    ```
    *Note: This linearly increases API usage and runtime.*

---

## 8. Usage

The core behavior of the system is controlled via CLI flags. For detailed control over agents, LLMs, API fallbacks, and performance tuning, refer to **Section 7.1 Configuration Scenarios & Tuning** for common adjustments, or **Section 9 Configuration** for the full schema.

### CLI (flags and what they do)
```
usage: hw4_tourguide [-h] [-v] --from ORIGIN --to DESTINATION
                     [--mode {live,cached}] [--config CONFIG]
                     [--log-level {DEBUG,INFO,WARNING,ERROR}]
                     [--output OUTPUT]
```

- `--from / --to` (required): origin/destination strings passed to route provider.
- `--mode {cached,live}` (default: cached):
  - `cached`: uses `data/routes/*.json`; no Google Maps calls. Agents still hit live sources if keys exist unless `use_live:false`/`mock_mode:true` in config.
  - `live`: calls Google Maps Directions/Geocoding (needs `GOOGLE_MAPS_API_KEY`); agents use live sources only if their keys are set.
- `--config PATH` (default: `config/settings.yaml`): central YAML for scheduler/orchestrator/agents/judge/logging/output.
- `--config PATH` (default: `config/settings.yaml`): central YAML for scheduler/orchestrator/agents/judge/logging/output. Use it to adjust `route_provider.max_steps` (default 8) when you need longer routes; increasing this directly scales API/LLM costs.
- `--log-level {DEBUG,INFO,WARNING,ERROR}` (default: INFO): overrides logging level.
- `--output PATH` (default: `output/final_route.json`): sets the JSON path; MD/CSV/checkpoints/logs follow the base rules below.
- `-v/--version`, `-h/--help`: metadata/help.

### Output behavior
- Default `--output`: creates run-specific folder under `output/` named `YYYY-MM-DD_HH-MM-SS_<origin>_to_<destination>` containing:
  - `final_route.json`, `summary.md`, `tour_export.csv`
  - `checkpoints/â€¦`
  - `logs/` (system + errors)
- Custom `--output /path/to/final.json`: writes `final.json`, `final.md`, `final.csv`, and checkpoints under `/path/to/`; logs remain in configured log dir (`logs/` by default).

### Cached routes note
`CachedRouteProvider` first looks for the SHA1 slug of `"<origin>-<destination>"` (first 12 chars). For `"Boston, MA"-"MIT"` the slug is `10dac2036c05`; the repo ships `data/routes/demo_boston_mit.json` and uses it when no slug match is found.

### Route length constraint
Live routes are capped to `config.route_provider.max_steps` steps (default: **8**) to keep Google Maps/LLM costs predictable. If you exceed this bound the CLI will fail with a helpful message; edit `config/settings.yaml` and rerun if you need longer legs. This limit also ensures agents/judge stay within their search budgets.

### What each flag changes at runtime
- Route source: `--mode cached` selects `CachedRouteProvider`; `live` selects `GoogleMapsProvider`.
- Agent sources: controlled by config (`agents.*.use_live`, `mock_mode`, `use_youtube_secondary`, etc.). Keys present â†’ live client; missing â†’ stub fallback (YouTube key allows SongAgent secondary).
- Logging/output layout: driven by `--output` and `logging` section in config; default uses run-specific folder under `output/`.

---

## 9. Configuration

### YAML Configuration (`config/settings.yaml`)

The `config/settings.yaml` file is the central control panel for the entire Route Enrichment Tour-Guide System. It allows you to fine-tune the behavior of the scheduler, orchestrator, agents, judge, logging, and output. You can override any of these settings via environment variables or CLI flags (see "Configuration Priority" below).

Each parameter includes an inline comment with its type, default value, and valid range.

#### 1. Scheduler Settings (`scheduler`)
*   **Purpose:** Controls the pace at which route steps are processed.
*   `interval` (Type: `float`, Default: `2.0`, Range: `0.5-10.0` seconds)
    *   **What it does:** Defines the delay between emitting each route step to the processing queue. A lower value speeds up the simulation, while a higher value slows it down, mimicking real-world travel time more closely.
    *   **Why change it:** Adjust for faster demos (`0.5s`) or more realistic simulation (`5.0s`).
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles the scheduler daemon thread. Setting to `false` is primarily for specific testing scenarios where direct control over task emission is needed.
    *   **Why change it:** Rarely changed; keep `true` for normal operation.

#### 2. Orchestrator Settings (`orchestrator`)
*   **Purpose:** Manages the concurrent execution of agents for each route step.
*   `max_workers` (Type: `int`, Default: `5`, Range: `1-20`)
    *   **What it does:** Sets the maximum number of parallel worker threads in the `ThreadPoolExecutor`. Each worker processes a single route step, dispatching agents concurrently.
    *   **Why change it:** Increase for faster processing on systems with more CPU cores or if agents are heavily I/O bound. Decrease to limit resource usage. `5` is a good balance for 3 agents + judge.
*   `shutdown_timeout` (Type: `float`, Default: `60.0` seconds)
    *   **What it does:** The maximum time the orchestrator waits for all active workers to complete their tasks during graceful shutdown.
    *   **Why change it:** Increase if you have very long-running agent tasks or many steps to allow them to finish before forcing termination.

#### 3. Agent Configuration (`agents`)
*   **Purpose:** Controls the behavior of the Video, Song, and Knowledge Agents, including LLM integration and API usage. These are global defaults that can be overridden per-agent.
*   **`use_llm_for_queries` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
    *   **What it does:** If `true`, agents will use an LLM (selected by `llm_provider`) to generate diverse search queries based on the route context. If `false`, agents fall back to simpler heuristic-based query generation (e.g., string concatenation).
    *   **Why change it:** Set to `false` for zero LLM cost runs, faster execution (avoids LLM latency), or if you don't have an LLM API key.
*   **`llm_provider` (MOST IMPORTANT) (Type: `str`, Default: `"auto"`, Valid: `"ollama"`, `"openai"`, `"claude"`, `"gemini"`, `"mock"`)**
    *   **What it does:** Specifies which LLM service to use for query generation.
    *   **Why change it:**
        *   `"auto"` (Recommended Default): Automatically selects the first available LLM from a priority list: Anthropic (Claude) > OpenAI > Gemini > Ollama > Mock. This is ideal for flexibility.
        *   `"claude"`, `"openai"`, `"gemini"`: Explicitly select a commercial LLM (requires API key in `.env`).
        *   `"ollama"`: Use a local Ollama instance (requires Ollama server running locally).
        *   `"mock"`: Force the use of a stub LLM, returning canned responses instantly (useful for testing without any external dependencies).
*   `llm_fallback` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, and an LLM call fails (timeout, error, budget exceeded), the agent will fall back to heuristic query generation instead of failing the step.
    *   **Why change it:** Keep `true` for robust operation. Set to `false` if you require strict LLM-only query generation and want the system to fail if the LLM is unavailable.
*   `llm_max_prompt_chars` (Type: `int`, Default: `5000`)
    *   **What it does:** Limits the length of the prompt sent to the LLM to control costs and avoid exceeding context windows. Prompts longer than this will be truncated.
    *   **Why change it:** Adjust if your prompt templates or route contexts become very long.
*   `llm_max_tokens` (Type: `int`, Default: `4000`)
    *   **What it does:** The maximum total tokens an agent can use across all LLM calls during a single run. This is a safety budget.
    *   **Why change it:** Increase for longer routes or if agents generate many queries; decrease to strictly control LLM spend.
*   **Individual Agent Settings (`agents.video`, `agents.song`, `agents.knowledge`)**
    *   **Purpose:** Fine-tune the behavior of each specific content agent.
    *   **`use_live` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, the agent attempts to use its live external API (YouTube for Video, Spotify for Song, Wikipedia/DuckDuckGo for Knowledge). If `false` or API keys are missing/invalid, it uses its internal stub/mock.
        *   **Why change it:** Set to `false` to force an agent into fully offline/stub mode, regardless of API key presence (e.g., for development, testing, or demonstrations without external network calls).
    *   `mock_mode` (Type: `bool`, Default: `false`)
        *   **What it does:** Forces the agent into a deterministic mock mode. Similar to `use_live: false`, but explicitly for mocking and testing scenarios.
        *   **Why change it:** For deterministic testing and debugging. If `true`, it overrides `use_live`.
    *   `search_limit` (Type: `int`, Default: `3`, Range: `1-10`)
        *   **What it does:** The number of search results (candidates) an agent will retrieve from its primary search API.
        *   **Why change it:** Increase to give the Judge more options, potentially improving content quality but increasing API calls/cost. Decrease to reduce API calls/cost.
    *   `max_search_calls_per_run` (Type: `int`, Default: `32`)
        *   **What it does:** A safety cap on the total number of search calls an individual agent can make during a single system run. This is crucial for managing API quotas.
        *   **Why change it:** For long routes, you might need to increase this, but be mindful of external API quotas. `32` provides a good buffer for 8-step routes.
    *   **`agents.song.use_youtube_secondary` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, and the primary Spotify search fails or returns insufficient results, the Song Agent will attempt to search YouTube for music-related content as a fallback.
        *   **Why change it:** Keep `true` for maximum content coverage. Set to `false` to only use Spotify (and stub if Spotify fails).
    *   **`agents.knowledge.use_secondary_source` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
        *   **What it does:** If `true`, the Knowledge Agent will use DuckDuckGo as a secondary search source alongside Wikipedia (or if Wikipedia fails).
        *   **Why change it:** Keep `true` for broader knowledge coverage. Set to `false` to only use Wikipedia (and stub if Wikipedia fails).

#### 4. Judge Settings (`judge`)
*   **Purpose:** Configures how content from agents is evaluated and selected for each route step.
*   **`scoring_mode` (MOST IMPORTANT) (Type: `str`, Default: `"llm"`, Valid: `"heuristic"`, `"llm"`, `"hybrid"`)**
    *   **What it does:** Determines the method the Judge uses to score agent-provided content.
    *   **Why change it:**
        *   `"llm"` (Recommended Default): Uses an LLM to evaluate content based on semantic understanding of the route context. Provides high-quality, nuanced scores and rationales (requires LLM API key).
        *   `"heuristic"`: Uses a rule-based scoring system (e.g., presence of keywords, metadata completeness). Cost-free and deterministic, but less intelligent.
        *   `"hybrid"`: Combines both LLM and heuristic scoring.
*   **`use_llm` (MOST IMPORTANT) (Type: `bool`, Default: `true`)**
    *   **What it does:** If `true`, the Judge will attempt to use an LLM for scoring (depending on `scoring_mode`). If `false`, LLM scoring is disabled entirely.
    *   **Why change it:** Set to `false` for zero LLM cost runs, faster execution, or if you don't have an LLM API key. Note: if `scoring_mode` is "llm" or "hybrid" and `use_llm` is `false`, it effectively falls back to heuristic.
*   `llm_provider` (Type: `str`, Default: `"auto"`, Valid: `"ollama"`, `"openai"`, `"claude"`, `"gemini"`, `"mock"`)
    *   **What it does:** Same as `agents.llm_provider`, but specifically for the Judge's LLM calls.
    *   **Why change it:** To use a different LLM for judging than for agent query generation, or to explicitly set it.
*   `llm_fallback` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, and the Judge's LLM call fails, it will fall back to heuristic scoring.
    *   **Why change it:** Keep `true` for robust operation.

#### 5. Logging Settings (`logging`)
*   **Purpose:** Controls how system events, errors, and debugging information are recorded.
*   `level` (Type: `str`, Default: `"INFO"`, Valid: `"DEBUG"`, `"INFO"`, `"WARNING"`, `"ERROR"`)
    *   **What it does:** Sets the minimum severity level for messages to be logged.
    *   **Why change it:** Set to `"DEBUG"` for verbose output during development/troubleshooting. Set to `"WARNING"` or `"ERROR"` to see only critical issues.
*   `file` (Type: `str`, Default: `"logs/system.log"`)
    *   **What it does:** Path to the main log file. All general system logs go here.
*   `error_file` (Type: `str`, Default: `"logs/errors.log"`)
    *   **What it does:** Path to a dedicated log file that only contains messages of `ERROR` severity or higher.
*   `modules` (Sub-section)
    *   **Purpose:** Allows fine-grained control over logging for specific parts of the system (e.g., agents, APIs, judge).
    *   **`modules.<name>.enabled`:** Toggles logging for that module.
    *   **`modules.<name>.file`:** Sets a separate log file for the module.
    *   **`modules.<name>.level`:** Sets the specific log level for that module.
    *   **Why change it:** For deep debugging, you might set `modules.agents.level: "DEBUG"` to see verbose agent activity without cluttering the main `system.log`.

#### 6. Output Settings (`output`)
*   **Purpose:** Configures where and how the final enriched route data and checkpoints are saved.
*   `base_dir` (Type: `str`, Default: `"output"`)
    *   **What it does:** The main directory where all run-specific output folders are created (e.g., `output/2025-12-01_10-30-00_Origin_to_Destination`).
    *   **Why change it:** To centralize all outputs to a different location.
*   `json_file`, `markdown_file`, `csv_file` (Type: `str`, Default: `"output/final_route.json"`, etc.)
    *   **What it does:** Specifies the default filenames for the final JSON, Markdown, and CSV reports. When using the default `--output` CLI flag, only the filename component of these values is used within the run-specific directory.
    *   **Why change it:** To change the default names of the output files.
*   `checkpoints_enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** If `true`, the system writes intermediate checkpoint files (JSON snapshots of pipeline state) at each major stage.
    *   **Why change it:** Keep `true` for debugging and auditability. Set to `false` to slightly reduce disk I/O, e.g., for performance benchmarking.
*   `checkpoint_retention_days` (Type: `int`, Default: `7`, Range: `0-30`)
    *   **What it does:** Automatically deletes checkpoint files older than this many days.
    *   **Why change it:** Set to `0` to keep checkpoints indefinitely. Adjust based on disk space and debugging needs.

#### 7. Route Provider Settings (`route_provider`)
*   **Purpose:** Defines how the system obtains the driving route.
*   **`mode` (MOST IMPORTANT) (Type: `str`, Default: `"live"`, Valid: `"live"`, `"cached"`)**
    *   **What it does:** Determines if the route is fetched live from Google Maps (`"live"`) or loaded from local JSON files (`"cached"`). This can also be set via the `--mode` CLI flag.
    *   **Why change it:** Set to `"cached"` for development, testing, and offline use to avoid Google Maps API calls and costs. Set to `"live"` for real-time route generation.
*   **`max_steps` (MOST IMPORTANT) (Type: `int`, Default: `8`, Range: `1-15`)**
    *   **What it does:** Limits the number of steps a route can have. This is a crucial control for managing API quotas and LLM costs.
    *   **Why change it:** Increase for longer trips (warning: directly increases API and LLM costs, and runtime). Decrease for shorter, cheaper runs.
*   `cache_dir` (Type: `str`, Default: `"data/routes"`)
    *   **What it does:** Directory where cached route JSON files are stored and looked up.
    *   **Why change it:** To point to a different local cache.

#### 8. Circuit Breaker Configuration (`circuit_breaker`)
*   **Purpose:** Implements the Circuit Breaker pattern to protect against cascading failures from unreliable external APIs.
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles the circuit breaker functionality globally.
    *   **Why change it:** Keep `true` for production-like resilience. Set to `false` only for specific debugging scenarios where you want API calls to always be attempted.
*   `failure_threshold` (Type: `int`, Default: `5`, Range: `3-10`)
    *   **What it does:** The number of consecutive failures before the circuit "opens", preventing further calls to the API.
    *   **Why change it:** Decrease to make the circuit breaker more sensitive (fail faster). Increase to make it more tolerant of transient errors.
*   `timeout` (Type: `float`, Default: `60.0` seconds)
    *   **What it does:** The time the circuit stays "open" before transitioning to "half-open" (allowing a single test call to check for recovery).
    *   **Why change it:** Adjust based on expected API recovery times.

#### 9. Metrics Configuration (`metrics`)
*   **Purpose:** Controls the collection and output of performance and usage metrics.
*   `enabled` (Type: `bool`, Default: `true`)
    *   **What it does:** Toggles metrics collection.
    *   **Why change it:** Set to `false` if you do not want any performance metrics collected or written.
*   `file` (Type: `str`, Default: `"logs/metrics.json"`)
    *   **What it does:** Path to the JSON file where collected metrics are saved.
*   `update_interval` (Type: `float`, Default: `5.0` seconds)
    *   **What it does:** How often the in-memory metrics are flushed and written to the `metrics.json` file.
    *   **Why change it:** Decrease for more frequent updates (higher overhead). Increase for less frequent updates.

### Environment Variables (`.env`)

Sensitive credentials are stored in `.env` (template: `.env.example`):

```bash
# Required for live mode
GOOGLE_MAPS_API_KEY=your_key_here

# Optional for enhanced features
YOUTUBE_API_KEY=your_key_here
SPOTIFY_CLIENT_ID=your_id_here
SPOTIFY_CLIENT_SECRET=your_secret_here
OPENAI_API_KEY=your_key_here  # For LLM judge
# Knowledge agent uses Wikipedia/DuckDuckGo which are keyless (no env needed)

Agent client selection
- Video: YouTube Data API if `YOUTUBE_API_KEY` set and `use_live: true`; otherwise stub fallback.
- Song: Spotify if `SPOTIFY_CLIENT_ID/SECRET` set and `use_live: true`; optional YouTube secondary if `YOUTUBE_API_KEY` and `use_youtube_secondary: true`; otherwise stub fallback.
- Knowledge: Wikipedia + DuckDuckGo (keyless, `use_live: true` by default); stub used when `use_live: false` or `mock_mode: true`.

Live vs offline modes
- Live: leave `use_live: true` (default) and set your API keys in `.env`. Requires outbound HTTPS to `www.googleapis.com`, `api.spotify.com`, `en.wikipedia.org`, `api.duckduckgo.com`.
- Offline/stub: set `use_live: false` or `mock_mode: true` per agent in `config/settings.yaml`. Cached routes still work; agents use stubs.

Circuit breaker & metrics
- Circuit breakers wrap external calls (YouTube/Spotify/Wikipedia/DDG); open after consecutive failures to avoid hammering APIs.
- MetricsCollector writes `logs/metrics.json` with counters (`api_calls.spotify`/`youtube`/`wikipedia`) and latencies (`agent.*.search_ms`, `agent.*.fetch_ms`).
- Tests: `pytest tests/test_circuit_breaker.py tests/test_metrics_collector.py tests/test_agent_metrics.py -v`
```

See `.env.example` for complete documentation of all environment variables.

### Configuration Priority

Settings are applied in this order (later overrides earlier):
1. Code defaults
2. `config/settings.yaml`
3. Environment variables (`.env`)
4. CLI flags (highest priority)

---

## 10. Technical Architecture

### System Overview

The system implements a multi-agent, event-driven pipeline designed for resilience and observability.

```
[Route Provider] â”€â”€(Task List)â”€â”€> [Scheduler] â”€â”€(Queue)â”€â”€> [Orchestrator]
                                                                  â”‚
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â–¼                           â–¼                           â–¼
                                [Video Agent]               [Song Agent]              [Knowledge Agent]
                                      â”‚                           â”‚                           â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚                           â”‚
                                                  â–¼                           â–¼
                                            [Judge Agent] â”€â”€(Decision)â”€â”€> [Output Writer]
```

### Component Architecture

1.  **Route Provider Layer**
    - **Abstraction**: Unified `RouteProvider` interface.
    - **Implementations**: `GoogleMapsProvider` (Live API) and `CachedRouteProvider` (JSON files).
    - **Key Feature**: Aggressive caching (ADR-003) reduces API costs by 99% during development.

2.  **Orchestration Core**
    - **Scheduler**: Dedicated daemon thread emitting tasks at configurable intervals (ADR-002).
    - **Orchestrator**: Uses `ThreadPoolExecutor` (ADR-007) to manage concurrent worker threads.
    - **Synchronization**: Thread-safe `queue.Queue` handles task handoff.

3.  **Agent Framework**
    - **Pattern**: Search-then-Fetch two-phase execution (ADR-004) for cost control.
    - **Intelligence**: Markdown-defined prompts (`.claude/agents/*.md`) loaded dynamically (ADR-013).
    - **Resilience**: All external calls wrapped in **Circuit Breakers** (ADR-010) with retry/backoff logic.

4.  **Judge & Evaluation**
    - **Hybrid Scoring**: Configurable weighted heuristics with optional LLM-based semantic evaluation.
    - **Logic**: Evaluates relevance, quality, and diversity of agent findings.

### Key Innovations

- **ðŸ›¡ï¸ Circuit Breaker Pattern (ADR-010)**: Prevents cascading failures by failing fast when external APIs (YouTube, Spotify) are down.
- **ðŸ†” Distributed Tracing (ADR-008)**: A unique `Transaction ID (TID)` follows every request from Route to Output, enabling precise log correlation across threads.
- **ðŸ’¾ File-Based Checkpoints (ADR-009)**: Every pipeline stage writes intermediate JSON artifacts (`output/checkpoints/{TID}/`), enabling "time-travel" debugging and replay.
- **ðŸ“Š Separated Metrics (ADR-011)**: Performance metrics (latencies, queue depth, API counts) are tracked separately from logs in `logs/metrics.json` for real-time analysis.
- **ðŸ§  Agent Intelligence Layer (ADR-013)**: Agent prompts are decoupled from code, defined in Markdown, allowing rapid prompt engineering without redeployment.

### Execution Pipeline

1.  **Initialization**: Config loaded, secrets injected, logging/metrics subsystems started.
2.  **Route Generation**: Route fetched (Live) or loaded (Cached), split into steps.
3.  **Scheduling**: Steps emitted to the queue at a human-readable pace.
4.  **Processing**: Orchestrator dispatches steps to workers; Agents execute concurrently.
5.  **Judgment**: Judge evaluates agent results and selects the best content.
6.  **Finalization**: Results aggregated into JSON, Markdown, and CSV reports.

### Documentation References

- **[C4 Architecture Diagrams](docs/architecture/c4_diagrams.md)**: Context, Container, Component, and Deployment views.
- **[Architecture Decision Records (ADR)](docs/architecture/adr_register.md)**: Detailed rationale for all 13 architectural decisions.

## 10a. Agent Intelligence: LLM-Based Query Generation

The system now features an advanced **Agent Intelligence Layer** (ADR-013) that allows agents to generate context-aware search queries using LLMs (Claude, OpenAI, etc.) instead of static heuristics.

### Key Capabilities
- **Markdown-Defined Prompts:** Agent behaviors are defined in `.claude/agents/*.md` files, allowing prompt engineering without code changes.
- **Context Awareness:** Prompts receive rich context (location, instructions, route hints) to generate targeted queries (e.g., inferring "University" implies "campus tour").
- **Safety & Fallback:** If the LLM is slow, fails, or is disabled, agents automatically revert to heuristic logic.

### Configuration
Enable or disable this feature in `config/settings.yaml`:
```yaml
agents:
  use_llm_for_queries: true
  llm_provider: "claude"  # or "openai", "gemini", "ollama"
  llm_fallback: true      # Use heuristics on failure
```

---

## 11. Testing

### Overview
- Pytest suite (~215 tests) covering unit logic, integration flows, concurrency, resilience, CLI, clients, and outputs.
- Coverage gate: 85% (current 86.21% on a clean run with dev deps).

### Test Suite Structure

#### 1. Core Pipeline & Orchestration
- `tests/test_scheduler.py`: Verifies precise interval-based task emission.
- `tests/test_orchestrator.py`: Validates thread pool management and task execution.
- `tests/test_route_provider.py`: Core routing logic (cached/live switching).
- `tests/test_route_provider_live.py`: Integration with Google Maps API.
- `tests/test_route_provider_errors.py`: Error handling for malformed routes/API failures.
- `tests/test_stub_route_provider.py`: Verifies deterministic fallback routing.

#### 2. Agents & Intelligence
- **Base Logic:** `tests/test_base_agent.py` (abstract class contracts).
- **Video Agent:** `tests/test_video_agent.py`, `tests/test_video_agent_duration.py`, `tests/test_video_agent_geosearch.py`
- **Song Agent:** `tests/test_song_agent.py`, `tests/test_song_agent_mood.py`, `tests/test_song_fallback.py` (secondary client fallback logic)
- **Knowledge Agent:** `tests/test_knowledge_agent.py`, `tests/test_knowledge_agent_authority.py`
- **LLM & Metrics:** `tests/test_agent_llm_queries.py`, `tests/test_agent_metrics.py`, `tests/test_agent_secondary.py`, `tests/test_resilience.py`

#### 3. Judge & Evaluation System
- `tests/test_judge.py`: Heuristic vs. LLM scoring logic.
- `tests/test_llm.py`: LLM provider integration (Anthropic/OpenAI/Gemini/Ollama).
- `tests/test_prompt_loader.py`: Dynamic loading of Markdown-based prompts.
- `tests/test_json_extraction.py`: Robust parsing of LLM JSON outputs.

#### 4. Resilience & Infrastructure
- **Resilience:** `tests/test_circuit_breaker.py`, `tests/test_resilience.py`, `tests/test_search_fetch.py`
- **Infrastructure:** `tests/test_config_loader.py`, `tests/test_logging.py`, `tests/test_logging_enhancements.py`, `tests/test_file_interface.py`, `tests/test_file_interface_errors.py`, `tests/test_output_writer.py`, `tests/test_metrics_collector.py`

#### 5. CLI & Entry Points
- `tests/test_cli.py`: Main entry point execution.
- `tests/test_cli_entry.py`: Argument mapping and exit codes.
- `tests/test_cli_parser.py`: Flag validation (`--mode`, `--config`).

#### 6. Integration & Concurrency
- `tests/test_integration.py`: End-to-end runs from Route -> Output.
- `tests/test_concurrency.py`: Thread safety, race condition checks, and queue integrity.

### Executing Tests

#### Quick Start
```bash
# Run all tests (fails if coverage < 85%)
pytest

# Run all tests with coverage report
pytest --cov=hw4_tourguide --cov-report=html
```

#### Targeted Execution
*Note: We use `--no-cov` for partial runs to avoid failing the global 85% coverage check.*

```bash
# Run only Agent-related tests
pytest tests/test_*_agent*.py --no-cov

# Run only Resilience tests
pytest -m resilience --no-cov

# Run a specific test file with verbose output
pytest tests/test_circuit_breaker.py -v --no-cov
```

#### Markers
The `pyproject.toml` defines strict markers for categorizing tests. Use `--no-cov` to check functionality without enforcing full coverage:

- `pytest -m unit --no-cov`: Fast, isolated tests using mocks.
- `pytest -m integration --no-cov`: Slower tests verifying component interaction.
- `pytest -m concurrency --no-cov`: Tests specifically checking thread safety.
- `pytest -m resilience --no-cov`: Tests verifying error handling and recovery.
- `pytest -m slow --no-cov`: Tests explicitly marked as slow-running.
- `pytest -m slow`: Tests explicitly marked as slow-running.

### Test Coverage & Quality

- **Target Coverage:** â‰¥85% (Enforced by CI)
- **Current Coverage:** 86.21%
- **Report:** Open `htmlcov/index.html` to view line-by-line coverage analysis.

### ISO/IEC 25010 Reliability Standards

The testing strategy explicitly targets key **ISO/IEC 25010** reliability characteristics:

1.  **Fault Tolerance:**
    - Verified by `tests/test_circuit_breaker.py` and `tests/test_resilience.py`.
    - Ensures the system operates gracefully despite external API failures (YouTube/Spotify outages).
2.  **Recoverability:**
    - Verified by `tests/test_file_interface.py` (checkpoints) and `tests/test_resilience.py` (retries).
    - Ensures the system can resume from interruptions and handle transient network errors via exponential backoff.
3.  **Maturity:**
    - Verified by high coverage (~87%) across core logic (`test_orchestrator.py`, `test_scheduler.py`) and edge cases (`test_route_provider_errors.py`).
    - Ensures the system meets production stability requirements through extensive unit and integration testing.
4.  **Availability:**
    - Verified by `tests/test_concurrency.py` and `tests/test_integration.py`.
    - Ensures the system remains responsive under load (multi-threaded execution) and correctly handles resources.

---

## 12. Troubleshooting

### Common Issues and Solutions

#### 1. Import Error: No module named 'hw4_tourguide'
**Solution:** Ensure venv is activated and package installed: `pip install .`

#### 2. Missing API Key Error
**Solution:** Copy `.env.example` to `.env` and add your API keys; or use `--mode cached` with agents set to `use_live:false` if offline.

#### 3. Google Maps API Quota Exceeded
**Solution:** Switch to cached mode: `--mode cached`; wait for quota reset; ensure `max_steps` not exceeded.

#### 4. Tests Failing with Coverage Below 85%
**Solution:** Identify gaps: `pytest --cov=hw4_tourguide --cov-report=term-missing`; run targeted suites (agents/judge/clients).

#### 5. CLI Not Found After Installation
**Solution:** Activate venv; reinstall: `pip install .`; verify `python -m hw4_tourguide --help`.

#### 6. Agent returns stub/unavailable in live mode
**Cause:** Missing service keys (YouTube/Spotify) or `use_live:false`.  
**Solution:** Set keys in `.env` and ensure `use_live:true` for that agent; check circuit breaker state.

#### 7. LLM scoring/query errors
**Cause:** Missing LLM keys or prompt files; provider timeouts.  
**Solution:** Provide Anthropic/OpenAI/Gemini key, or set `use_llm:false` (judge) / `use_llm_for_queries:false` (agents). Verify prompts under `.claude/agents/` are packaged (they are).

#### 8. No outputs/logs where expected
**Cause:** Custom `--output` moves artifacts; logs stay in configured log dir.  
**Solution:** Use default `--output` to get per-run folder under `output/`; with custom output, check sibling MD/CSV and `logs/`.

#### 9. Circuit breaker opens (YouTube/Spotify/Wikipedia)
**Cause:** Repeated failures/timeouts.  
**Solution:** Wait for breaker timeout or reduce `failure_threshold`; verify network/keys; cached mode uses stubs.

For deeper troubleshooting, see `docs/troubleshooting.md` (if present) and logs/checkpoints under the run directory.

---

## 13. Research & Analysis

### Studies Planned (Phase 6)

1. **Orchestration Efficiency**: Parallelism, queue depth, system throughput
2. **Cost Analysis**: API usage tracking, live vs cached comparison
3. **Judge LLM Impact**: Heuristic vs LLM-assisted scoring quality
4. **Parameter Sensitivity**: Optimal configuration values

Results will be documented in `docs/analysis/results.ipynb` with:
- â‰¥4 plot types (bar, line, scatter, heatmap)
- LaTeX formulas for metrics
- Statistical analysis with confidence intervals

See `docs/cost_analysis.md` for API cost breakdown and optimization strategies (coming in M8.2).

---

## 14. UX Heuristics & CLI Usability

Nielsenâ€™s 10 heuristics mapped to our CLI/log experience (see `docs/ux/heuristics.md` for full details and commands):
- **Visibility of status:** Structured logs with event tags (`Scheduler`, `Orchestrator`, `Agent`, `Judge`, `Error`). Verify: run cached with `--log-level DEBUG`, `tail -n 20 output/<run>/logs/system.log`.
- **Match to real world:** Travel-friendly flags (`--from/--to/--mode`); outputs include steps, distance, duration. Verify: `python -m hw4_tourguide --help`.
- **User control/freedom:** Choose cached vs live; force stubs via `use_live:false`/`mock_mode:true`; Ctrl+C leaves checkpoints/logs. Verify: interrupt a cached run and inspect `output/<run>/checkpoints/`.
- **Consistency/standards:** Stable flag names, log format `TIMESTAMP | LEVEL | MODULE | EVENT_TAG | MESSAGE`; config keys mirror docs. Verify: `grep -E "Scheduler|Orchestrator|Agent|Judge" output/<run>/logs/system.log`.
- **Error prevention/recovery:** Config validation, fallbacks to cached/stubs, circuit breaker warnings. Verify: `pytest tests/test_config_loader.py -k validation`; inspect warnings in logs.
- **Recognition over recall:** Sensible defaults (cached mode, default output paths, inline YAML comments), examples in `--help`. Verify: `python -m hw4_tourguide --help`.
- **Flexibility/efficiency:** YAML + CLI overrides, mock mode, adjustable intervals/workers. Verify: run with custom `--config` and `--log-level DEBUG`.
- **Minimal clutter:** Concise stdout; details in logs/MD/CSV. Verify: review `summary.md`/`tour_export.csv` in run output.

---

## 15. Quality Standards Summary

This project adheres to the **ISO/IEC 25010 Software Quality Model**, ensuring a production-grade standard of engineering. A comprehensive audit of the system against all 8 quality characteristics is available in [**docs/quality/iso_25010_assessment.md**](docs/quality/iso_25010_assessment.md).

### Key Quality Characteristics

#### ðŸ›¡ï¸ Reliability (Outstanding)
The system is designed to be fault-tolerant and recoverable in unstable network environments.
- **Fault Tolerance:** Circuit Breakers (ADR-010) prevent cascading failures from external API outages. Verified by `tests/test_circuit_breaker.py`.
- **Recoverability:** Checkpoint system (ADR-009) persists state at every step, allowing resume-on-failure. Verified by `tests/test_file_interface.py`.
- **Maturity:** High test coverage (~87%) across happy paths and edge cases ensures stability.

#### ðŸ”§ Maintainability (Outstanding)
The codebase prioritizes modularity and ease of modification.
- **Modularity:** Strict separation of concerns (Agents, Core, Tools, Interfaces) enforced by `BaseAgent` contracts. Verified by `tests/test_base_agent.py`.
- **Analyzability:** Comprehensive Architecture Decision Records (ADRs) and type-hinted code facilitate rapid understanding.
- **Testability:** Extensive unit and integration suites enable safe refactoring.

#### ðŸ§© Usability (Outstanding)
The system offers a superior Developer Experience (DX) and operational clarity.
- **Observability:** Structured, event-tagged logging facilitates rapid debugging. Verified by `tests/test_logging_enhancements.py`.
- **Error Protection:** Robust config validation falls back to safe defaults (e.g., cached mode) when keys are missing. Verified by `tests/test_config_loader.py`.
- **Clarity:** Comprehensive CLI help and consistent flag naming conventions.

#### âš¡ Performance Efficiency (Excellent)
- **Concurrency:** Event-driven architecture with `ThreadPoolExecutor` maximizes throughput. Verified by `tests/test_concurrency.py`.
- **Resource Usage:** Aggressive caching strategies minimize expensive API calls. Verified by `tests/test_route_provider.py`.

*For the full breakdown of Functional Suitability, Compatibility, Security, and Portability, please refer to the detailed assessment document.*

---

## 16. Project Status & Roadmap

### Current Status: Phase 7 - Preflight & Submission

**Completed (highlights):**
- âœ… M0-6: PRD, architecture (C4/ADRs), config/logging, schemas, UX heuristics
- âœ… M7.0-7.11: Core pipeline (Route Provider -> Scheduler -> Orchestrator -> Agents -> Judge -> Output)
- âœ… M7.12-7.19: Resilience tests, LLM query generation (ADR-013), Song Agent fallback, Circuit Breakers
- âœ… Gate 4: Passed (Core Implementation Complete)
- âœ… M8.1-8.5: Research Analysis, Cost Analysis, Documentation cross-check
- âœ… Phase 6: Research & Documentation complete

**In Progress:**
- ðŸŸ¡ Phase 7: Final Package Verification & Submission

**Upcoming:**
- Release v0.1.1 (Final Submission)

See `PROGRESS_TRACKER.md` and `Missions_Route_Enrichment_Tour_Guide_System.md` for detailed roadmap.

---

## 17. Extensibility & Maintenance

**New Features**
- New agent type: subclass `BaseAgent`, inject clients/tools, add prompt in `hw4_tourguide/prompts/agents/<agent>_agent.md`, expose config keys under `agents.<name>` in `config/settings.yaml`, and register in `_build_agents` (src/hw4_tourguide/__main__.py). Add unit + integration tests.
- New route provider: subclass `RouteProvider`, reuse retries/CB/metrics, emit the existing task schema, and wire it into `_select_route_provider` with a config flag. Include cache/checkpoint handling if applicable.
- New outputs/rerankers: extend `OutputWriter` for extra formats or add a post-search rerank hook in agents/judge; guard with config flags and keep schemas stable for JSON/MD/CSV.

**Maintenance Considerations**
- Configuration-first: document new settings in `config/settings.yaml` (with sane defaults) and keep CLI overrides consistent. Update ADRs when changing architecture.
- Prompts: maintain packaged prompts in `hw4_tourguide/prompts/agents`; keep `.claude/agents` in sync for local editing. Ensure `prompt_loader` paths stay valid.
- Observability: preserve structured logging, checkpoints, and metrics counters; keep circuit-breaker thresholds/timeouts tuned (`circuit_breaker.*`, agent timeouts, `route_provider.max_steps`).
- Contracts & tests: respect output schemas and validator expectations; keep coverage â‰¥85% with resilience/concurrency tests when touching scheduler/orchestrator/agents/judge.
- Packaging hygiene: include new data assets via `tool.setuptools.package-data` (or move defaults under `hw4_tourguide/`) so installs remain runnable without the repo checkout.

**Future Enhancements**
- Stronger LLM guardrails: stricter JSON extraction/validation for query generation and judge scoring; optional schema validation before use.
- Pluggable rerankers/judge strategies: add embedding/LLM rerank of multi-source results; make scoring mode a pluggable strategy with config toggles.
- Dynamic routing & timing: optional mid-route updates or waypoint insertion, improved scheduler timing to mirror live ETA cadence, and smarter cache priming for repeated corridors.
- Extended sources: richer secondary sources (e.g., local/offline datasets) with source weighting in judge scoring; configurable via `agents.use_secondary_source`-style flags.

---

## 18. Documentation

- **Core specs:** [PRD_Route_Enrichment_Tour_Guide_System.md](PRD_Route_Enrichment_Tour_Guide_System.md), [Missions_Route_Enrichment_Tour_Guide_System.md](Missions_Route_Enrichment_Tour_Guide_System.md), [HW4_Project_Mission.md](HW4_Project_Mission.md).
- **Architecture & APIs:** [docs/architecture/adr_register.md](docs/architecture/adr_register.md), [docs/architecture/c4_diagrams.md](docs/architecture/c4_diagrams.md), [docs/api_reference.md](docs/api_reference.md), contracts: [route_schema.json](docs/contracts/route_schema.json), [task_schema.json](docs/contracts/task_schema.json), [agent_result_schema.json](docs/contracts/agent_result_schema.json), [judge_decision_schema.json](docs/contracts/judge_decision_schema.json).
- **Research & analysis:** [docs/research_plan.md](docs/research_plan.md), [docs/analysis/results.ipynb](docs/analysis/results.ipynb), [docs/cost_analysis.md](docs/cost_analysis.md).
- **Quality & UX:** [docs/quality/iso_25010_assessment.md](docs/quality/iso_25010_assessment.md), [docs/ux/heuristics.md](docs/ux/heuristics.md).
- **Prompts & dev log:** [docs/prompt_log/](docs/prompt_log/) (e.g., [001_architecture_design_session.md](docs/prompt_log/001_architecture_design_session.md), [orchestrator_prompt.md](docs/prompt_log/orchestrator_prompt.md)); runtime prompt templates in [src/hw4_tourguide/prompts/agents/](src/hw4_tourguide/prompts/agents/) mirror `.claude/agents/`.
- **Screenshots & evidence:** [docs/screenshots/GALLERY_TEMPLATE.md](docs/screenshots/GALLERY_TEMPLATE.md) (gallery placeholder for logs/CLI/output captures).

---

## 19. Contributing

### Development Workflow
1. Fork/clone repository
2. Create venv + install deps: `pip install .` (and `".[dev]"` for tests)
3. Create feature branch: `git checkout -b feature/<name>`
4. Make changes + add tests/docs
5. Run tests: `pytest` (coverage gate 85%)
6. Commit with clear message; push branch; open PR

### Code Style & QA
- PEP8 + type hints; concise docstrings where helpful
- Add/maintain tests for new behavior; keep coverage â‰¥85%
- Prefer dependency injection for agents/tools/clients; keep modules cohesive
- Update docs/README/ADR when behavior or interfaces change

### Testing Requirements
- Run full suite: `pytest` (coverage gate 85%) before PRs; focus on concurrency/resilience tests when touching scheduler/orchestrator/agents/judge.
- Add unit/integration tests for new features or schema changes; keep deterministic outputs for JSON/MD/CSV.
- Confirm cached + live flags still parse: `python -m hw4_tourguide --help`; dry-run cached demo when touching CLI/config.
- Verify docs stay in sync when adding config flags or prompts (update README + ADRs as needed).

---

## 20. License & Attribution

- **License:** MIT (educational use for M.Sc. Data Science coursework)
- **Course:** LLMs and Multi-Agent Orchestration (Dr. Segal Yoram)
- **Date:** November 2025
- **Project:** Route Enrichment Tour-Guide System (HW4)
- **Authors:** Igor Nazarenko, Tom Ron, Roie Gilad

### Acknowledgments
- Dr. Segal Yoram for guidance
- Open-source community for core libraries

### Third-Party Libraries (key)
- requests, pyyaml, python-dotenv, pytest/pytest-cov, numpy/pandas (dev), jupyter/matplotlib/seaborn (dev)
- Optional live clients: YouTube Data API, Spotify Web API, Wikipedia/DuckDuckGo, LLM providers (Anthropic/OpenAI/Gemini/Ollama/Mock)

### Credits / References
- Architecture & ADRs: `docs/architecture/*`
- API Reference: `docs/api_reference.md`
- UX Heuristics: `docs/ux/heuristics.md`
- Quality Assessment: `docs/quality/iso_25010_assessment.md`
- References (selected):
  - Python concurrent futures (ThreadPoolExecutor): https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor
  - Prompt-template agents (Markdown definitions): https://python.langchain.com/docs/modules/model_io/prompts/
  - Multi-agent orchestration patterns (LangGraph): https://python.langchain.com/docs/langgraph/
  - Python logging best practices: https://docs.python.org/3/howto/logging-cookbook.html
  - Google Maps Directions API: https://developers.google.com/maps/documentation/directions
  - YouTube Data API v3 (search/fetch): https://developers.google.com/youtube/v3/docs
  - Spotify Web API (tracks/search): https://developer.spotify.com/documentation/web-api
  - Wikipedia REST API: https://en.wikipedia.org/api/rest_v1/
  - DuckDuckGo Instant Answer API: https://api.duckduckgo.com/api
  - Anthropic prompt design (Markdown templates): https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering
  - ISO/IEC 25010 quality model: https://iso25000.com/index.php/en/iso-25000-standards/iso-25010

### Citation
If you use this system or methodology in your work, please cite:

```bibtex
@software{route_enrichment_tourguide_2025,
  author    = {Nazarenko, Igor and Ron, Tom and Gilad, Roie},
  title     = {Route Enrichment Tour-Guide System},
  year      = {2025},
  course    = {LLMs and Multi-Agent Orchestration},
  instructor= {Dr. Segal Yoram},
  institution = {M.Sc. Data Science Program}
}
```

### Educational Value
- **Technical Skills:** Multi-agent orchestration with ThreadPoolExecutor + Queue; API client integration (Google Maps, YouTube, Spotify, Wikipedia/DDG); LLM prompt templating via packaged Markdown; circuit breakers/backoff/checkpointing; configuration-first design (YAML + CLI overrides); structured logging and metrics.
- **Problem-Solving Skills:** Cost control via cached routes and stub agents; graceful degradation when keys are missing; schema validation to keep outputs deterministic; prompt-driven behavior tuning without code changes.
- **Professional Skills:** ADR-driven architecture choices; comprehensive documentation (PRD, API reference, UX heuristics, quality audit); reproducible packaging and testing discipline (coverage gate, concurrency/resilience tests); clear CLI/README for graders and users.

---

## 21. Screenshots & Sample Outputs

A complete gallery of visual evidence is available in [docs/screenshots/GALLERY_TEMPLATE.md](docs/screenshots/GALLERY_TEMPLATE.md), where you can drop CLI, log, JSON, and Markdown snapshots that match the excerpts below.

### CLI Help Output

```
$ python -m hw4_tourguide --help
usage: hw4_tourguide [-h] [-v] [--from ORIGIN] [--to DESTINATION]
                     [--mode {live,cached}] [--config CONFIG]
                     [--log-level {DEBUG,INFO,WARNING,ERROR}] [--output OUTPUT]
...
```

### Sample Logs

```
2024-11-22 10:15:23 | INFO | Scheduler | EMIT | Step 1/5: MIT Campus (TID: abc123)
2024-11-22 10:15:25 | INFO | Orchestrator | DISPATCH | TID: abc123, Workers: 3/5 active
2024-11-22 10:15:26 | INFO | VideoAgent | SEARCH | Query: "MIT campus tour" | Results: 3 videos
2024-11-22 10:15:26 | INFO | SongAgent | SEARCH | Query: "MIT music" | Results: 3 tracks
2024-11-22 10:15:26 | INFO | KnowledgeAgent | SEARCH | Query: "MIT history" | Results: 3 articles
2024-11-22 10:15:28 | INFO | Judge | SCORE | TID: abc123 | Overall: 85, Video: 90, Song: 80, Knowledge: 85
```

These log lines are extracted from a cached run stored in `logs/system.log`; the gallery template links directly to similar captures.

### Sample Output JSON (final_route.json excerpt)
```json
[
  {
    "step_number": 1,
    "location": "MIT Campus",
    "instructions": "Head northwest on Main St",
    "agents": {
      "video": {"status": "ok", "metadata": {"title": "MIT Campus Tour", "url": "https://youtu.be/demo"}},
      "song": {"status": "ok", "metadata": {"title": "Road Trip Beats", "url": "https://open.spotify.com/track/demo"}},
      "knowledge": {"status": "ok", "metadata": {"title": "MIT History", "url": "https://en.wikipedia.org/wiki/Massachusetts_Institute_of_Technology"}}
    },
    "judge": {
      "chosen_agent": "video",
      "overall_score": 90,
      "rationale": "Video best matches location context",
      "chosen_content": {"title": "MIT Campus Tour", "url": "https://youtu.be/demo"}
    }
  }
]
```

### Sample Markdown Report (summary.md excerpt)
```markdown
## Step 1: MIT Campus
Instructions: Head northwest on Main St

### Judge's Decision for MIT Campus
Chosen Content Type: **Video**
Title: [MIT Campus Tour](https://youtu.be/demo)
Overall Score: `90`
Rationale: Video best matches location context.
- Video rationale: Heuristic score breakdown: Presence=100, Quality=80, Relevance=90.
- Song rationale: Heuristic score breakdown: Presence=100, Quality=80, Relevance=70.
- Knowledge rationale: Heuristic score breakdown: Presence=100, Quality=90, Relevance=75.
```

These snippets are representative of the actual files generated under `output/<run>/final_route.json` and `output/<run>/summary.md`; capture them via the gallery link for easy reference.

See `docs/screenshots/` for terminal captures (coming in M6).

---

## 22. Support & Contact

- **Issues/PRs:** via repository tracker
- **Authors:** Igor Nazarenko, Tom Ron, Roie Gilad
- **Course:** LLMs and Multi-Agent Orchestration (Dr. Segal Yoram)

### Final Notes
- Default cached demo enables offline grading; live mode requires keys.
- Per-run outputs (JSON/MD/CSV), logs, and checkpoints provide auditability.

---

*README generated for hw4_tourguide v0.1.0 | Last updated: 2024-11-22*
